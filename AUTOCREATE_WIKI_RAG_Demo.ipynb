{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e968b86",
   "metadata": {},
   "source": [
    "# ğŸ¤– AUTOCREATE WIKI RAG ã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/USERNAME/AUTOCREATE/blob/main/AUTOCREATE_WIKI_RAG_Demo.ipynb)\n",
    "\n",
    "## æ¦‚è¦\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€**AUTOCREATE**ã®æ—¢å­˜WIKIãƒŠãƒ¬ãƒƒã‚¸ã‚’æ´»ç”¨ã—ãŸRAGï¼ˆRetrieval-Augmented Generationï¼‰ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ãƒ»ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚\n",
    "\n",
    "### ğŸ¯ ç›®æ¨™\n",
    "- ChromaDBã‚’ä½¿ã£ãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰\n",
    "- æ—¢å­˜WIKIæ–‡æ›¸ã‹ã‚‰ã®è‡ªå‹•ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ä½œæˆ\n",
    "- è‡ªç„¶è¨€èªã«ã‚ˆã‚‹è³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿç¾\n",
    "\n",
    "### ğŸš€ ç‰¹å¾´\n",
    "- **AIç¤¾é•·Ã—ç„¡è·CTOä½“åˆ¶**ã«ã‚ˆã‚‹é©æ–°çš„ãªAIè‡ªå‹•é–‹ç™º\n",
    "- å¤šè¨€èªå¯¾å¿œï¼ˆæ—¥æœ¬èªãƒ»è‹±èªï¼‰\n",
    "- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ãƒ»å›ç­”ç”Ÿæˆ\n",
    "- Gradio Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹é€£æº\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ï¸âƒ£ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install -q chromadb>=0.4.22\n",
    "!pip install -q langchain>=0.1.0\n",
    "!pip install -q langchain-community>=0.0.13\n",
    "!pip install -q sentence-transformers>=2.2.2\n",
    "!pip install -q gradio>=4.0.0\n",
    "!pip install -q python-dotenv>=1.0.0\n",
    "!pip install -q markdown>=3.5.0\n",
    "!pip install -q beautifulsoup4>=4.12.0\n",
    "\n",
    "print(\"âœ… ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ï¸âƒ£ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# ChromaDB & LangChain\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "# ãã®ä»–ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ç’°å¢ƒè¨­å®š\n",
    "load_dotenv()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"ğŸ“š ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "print(f\"ğŸ—‚ï¸ ChromaDB ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {chromadb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd44c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ï¸âƒ£ WIKI RAGã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹å®šç¾©\n",
    "class WikiRAGSystem:\n",
    "    \"\"\"AUTOCREATE WIKI RAGã‚·ã‚¹ãƒ†ãƒ \"\"\"\n",
    "    \n",
    "    def __init__(self, wiki_paths: List[str] = None, chroma_path: str = None):\n",
    "        \"\"\"åˆæœŸåŒ–\"\"\"\n",
    "        # Colabç’°å¢ƒç”¨ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹è¨­å®š\n",
    "        if wiki_paths is None:\n",
    "            wiki_paths = []\n",
    "            # ã‚µãƒ³ãƒ—ãƒ«WIKI ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ\n",
    "            if os.path.exists(\"/content/wikigit\"):\n",
    "                wiki_paths.append(\"/content/wikigit\")\n",
    "            if os.path.exists(\"/content/docs\"):\n",
    "                wiki_paths.append(\"/content/docs\")\n",
    "            # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒç”¨\n",
    "            if os.path.exists(\"/workspaces/AUTOCREATE/wikigit\"):\n",
    "                wiki_paths.append(\"/workspaces/AUTOCREATE/wikigit\")\n",
    "            if os.path.exists(\"/workspaces/AUTOCREATE/docs\"):\n",
    "                wiki_paths.append(\"/workspaces/AUTOCREATE/docs\")\n",
    "        \n",
    "        self.wiki_paths = wiki_paths\n",
    "        self.chroma_path = chroma_path or \"/tmp/chroma_wiki_rag\"\n",
    "        self.collection_name = \"wiki_knowledge\"\n",
    "        \n",
    "        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²å™¨\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \".\", \" \", \"\"]\n",
    "        )\n",
    "        \n",
    "        # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆå¤šè¨€èªå¯¾å¿œï¼‰\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"intfloat/multilingual-e5-large\",\n",
    "            model_kwargs={'device': 'cpu'},\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "        \n",
    "        # ChromaDBè¨­å®š\n",
    "        self.chroma_client = None\n",
    "        self.vectorstore = None\n",
    "        \n",
    "        print(f\"ğŸš€ WIKI RAGã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ\")\n",
    "        print(f\"ğŸ“ WIKIãƒ‘ã‚¹: {self.wiki_paths}\")\n",
    "        print(f\"ğŸ’¾ Chromaãƒ‘ã‚¹: {self.chroma_path}\")\n",
    "    \n",
    "    def initialize_chroma(self):\n",
    "        \"\"\"ChromaDBåˆæœŸåŒ–\"\"\"\n",
    "        try:\n",
    "            os.makedirs(self.chroma_path, exist_ok=True)\n",
    "            \n",
    "            self.chroma_client = chromadb.PersistentClient(\n",
    "                path=self.chroma_path,\n",
    "                settings=Settings(\n",
    "                    anonymized_telemetry=False,\n",
    "                    allow_reset=True\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆãƒ»å–å¾—\n",
    "            try:\n",
    "                collection = self.chroma_client.get_collection(name=self.collection_name)\n",
    "                print(f\"âœ… æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{self.collection_name}' ã‚’å–å¾—\")\n",
    "            except:\n",
    "                collection = self.chroma_client.create_collection(\n",
    "                    name=self.collection_name,\n",
    "                    metadata={\"description\": \"AUTOCREATE WIKI Knowledge Base\"}\n",
    "                )\n",
    "                print(f\"ğŸ†• æ–°è¦ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{self.collection_name}' ã‚’ä½œæˆ\")\n",
    "            \n",
    "            # LangChain Vectorstoreä½œæˆ\n",
    "            self.vectorstore = Chroma(\n",
    "                client=self.chroma_client,\n",
    "                collection_name=self.collection_name,\n",
    "                embedding_function=self.embeddings\n",
    "            )\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ChromaDBåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "            return False\n",
    "\n",
    "print(\"âœ… WikiRAGSystemã‚¯ãƒ©ã‚¹ãŒå®šç¾©ã•ã‚Œã¾ã—ãŸï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be6e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ï¸âƒ£ ã‚µãƒ³ãƒ—ãƒ«WIKIãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ\n",
    "def create_sample_wiki_data():\n",
    "    \"\"\"ãƒ‡ãƒ¢ç”¨ã®ã‚µãƒ³ãƒ—ãƒ«WIKIãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ\"\"\"\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "    sample_dir = \"/tmp/sample_wiki\"\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«WIKIã‚³ãƒ³ãƒ†ãƒ³ãƒ„\n",
    "    wiki_contents = [\n",
    "        {\n",
    "            \"filename\": \"Home.md\",\n",
    "            \"content\": \"\"\"# AUTOCREATE ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ\n",
    "\n",
    "## æ¦‚è¦\n",
    "AUTOCREATEã¯ã€ä¸–ç•Œåˆã®ã€ŒAIç¤¾é•·Ã—ç„¡è·CTOä½“åˆ¶ã€ã«ã‚ˆã‚‹é©æ–°çš„ãªAIè‡ªå‹•é–‹ç™ºãƒ»AIè¦–è¦šè‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚\n",
    "\n",
    "## ç‰¹å¾´\n",
    "- è‡ªç„¶è¨€èªã§ã®é–‹ç™ºæŒ‡ç¤ºãŒå¯èƒ½\n",
    "- OCR + RPA ã«ã‚ˆã‚‹è¦–è¦šè‡ªå‹•åŒ–\n",
    "- ãƒªãƒ¦ãƒ¼ã‚¹æ¥­ç•Œç‰¹åŒ–ã® AI ã‚·ã‚¹ãƒ†ãƒ \n",
    "- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹æˆ¦ç•¥\n",
    "\n",
    "## ç†å¿µ\n",
    "ã€Œæ€ã£ãŸã“ã¨ã‚’è‡ªç„¶è¨€èªã§ä¼ãˆã‚‹ã ã‘ã§ã€AIãŒè‡ªå‹•çš„ã«ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ã€\n",
    "ã“ã‚ŒãŒç§ãŸã¡ã®ç›®æŒ‡ã™æœªæ¥ã§ã™ã€‚\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"filename\": \"AI-Vision-Automation.md\", \n",
    "            \"content\": \"\"\"# AIè¦–è¦šè‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ \n",
    "\n",
    "## æ¦‚è¦\n",
    "AIè¦–è¦šè‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ç”»é¢èªè­˜ãƒ»OCRãƒ»RPA ã‚’çµ„ã¿åˆã‚ã›ãŸé©æ–°çš„ãªè‡ªå‹•åŒ–ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚\n",
    "\n",
    "## æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯\n",
    "- **OCR**: Google Apps Script + Vision API\n",
    "- **RPA**: Python + Selenium + xdotool\n",
    "- **AIåˆ†æ**: LLM + Visionæ¨¡å‹\n",
    "- **UI**: Gradio + Jupyter Notebook\n",
    "\n",
    "## ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹\n",
    "1. **kinkaimasu.jpè‡ªå‹•åŒ–**: è²·å–ä¾¡æ ¼ã®è‡ªå‹•å–å¾—\n",
    "2. **ãƒ‡ãƒ¼ã‚¿å…¥åŠ›è‡ªå‹•åŒ–**: OCRçµæœã®è‡ªå‹•å…¥åŠ›\n",
    "3. **ç”»é¢æ“ä½œè‡ªå‹•åŒ–**: ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼åˆ†æã«ã‚ˆã‚‹è‡ªå‹•æ“ä½œ\n",
    "\n",
    "## å°å…¥åŠ¹æœ\n",
    "- æ‰‹ä½œæ¥­å‰Šæ¸›: 90%ä»¥ä¸Š\n",
    "- å‡¦ç†é€Ÿåº¦å‘ä¸Š: 10å€ä»¥ä¸Š\n",
    "- ã‚¨ãƒ©ãƒ¼ç‡å‰Šæ¸›: 95%ä»¥ä¸Š\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"filename\": \"Gradio-System.md\",\n",
    "            \"content\": \"\"\"# Gradioã‚·ã‚¹ãƒ†ãƒ \n",
    "\n",
    "## æ¦‚è¦\n",
    "Gradioã¯Webãƒ™ãƒ¼ã‚¹ã®æ©Ÿæ¢°å­¦ç¿’ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ç°¡å˜ã«ä½œæˆã§ãã‚‹Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚\n",
    "\n",
    "## AUTOCREATE ã§ã®æ´»ç”¨\n",
    "- OCRè§£æã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹\n",
    "- AIè¦–è¦šè‡ªå‹•åŒ–ãƒ‡ãƒ¢\n",
    "- WIKI RAG ã‚·ã‚¹ãƒ†ãƒ \n",
    "- ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼åˆ†æãƒ„ãƒ¼ãƒ«\n",
    "\n",
    "## å®Ÿè£…ä¾‹\n",
    "```python\n",
    "import gradio as gr\n",
    "\n",
    "def ocr_analyze(image):\n",
    "    # OCRå‡¦ç†\n",
    "    return \"OCRçµæœ\"\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=ocr_analyze,\n",
    "    inputs=\"image\",\n",
    "    outputs=\"text\"\n",
    ")\n",
    "interface.launch()\n",
    "```\n",
    "\n",
    "## åˆ©ç‚¹\n",
    "- è¿…é€Ÿãªãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°\n",
    "- éæŠ€è¡“è€…ã§ã‚‚åˆ©ç”¨å¯èƒ½\n",
    "- Colabé€£æº\n",
    "- å…±æœ‰ãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ãŒç°¡å˜\n",
    "\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"filename\": \"ChromaDB-RAG.md\",\n",
    "            \"content\": \"\"\"# ChromaDB RAGã‚·ã‚¹ãƒ†ãƒ \n",
    "\n",
    "## æ¦‚è¦\n",
    "ChromaDBã¯é«˜æ€§èƒ½ãªãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã€RAGï¼ˆRetrieval-Augmented Generationï¼‰ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã«æœ€é©ã§ã™ã€‚\n",
    "\n",
    "## ç‰¹å¾´\n",
    "- é«˜é€Ÿãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢\n",
    "- æ°¸ç¶šåŒ–ã‚µãƒãƒ¼ãƒˆ\n",
    "- å¤šæ§˜ãªåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«å¯¾å¿œ\n",
    "- ã‚·ãƒ³ãƒ—ãƒ«ãªAPI\n",
    "\n",
    "## AUTOCREATE ã§ã®å®Ÿè£…\n",
    "1. **ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰**: æ—¢å­˜WIKIã®è‡ªå‹•ãƒ™ã‚¯ãƒˆãƒ«åŒ–\n",
    "2. **è³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ **: è‡ªç„¶è¨€èªã«ã‚ˆã‚‹æ¤œç´¢ãƒ»å›ç­”\n",
    "3. **å¤šè¨€èªå¯¾å¿œ**: æ—¥æœ¬èªãƒ»è‹±èªã®åŒæ™‚å¯¾å¿œ\n",
    "\n",
    "## æŠ€è¡“è©³ç´°\n",
    "- **åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«**: intfloat/multilingual-e5-large\n",
    "- **ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²**: RecursiveCharacterTextSplitter\n",
    "- **æ¤œç´¢æ‰‹æ³•**: ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹\n",
    "\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\n",
    "    created_files = []\n",
    "    for item in wiki_contents:\n",
    "        file_path = os.path.join(sample_dir, item[\"filename\"])\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(item[\"content\"])\n",
    "        created_files.append(file_path)\n",
    "    \n",
    "    print(f\"ğŸ“ {len(created_files)}å€‹ã®ã‚µãƒ³ãƒ—ãƒ«WIKIãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ:\")\n",
    "    for file_path in created_files:\n",
    "        print(f\"  - {file_path}\")\n",
    "    \n",
    "    return sample_dir\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Ÿè¡Œ\n",
    "sample_wiki_dir = create_sample_wiki_data()\n",
    "print(f\"\\nâœ… ã‚µãƒ³ãƒ—ãƒ«WIKIãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "print(f\"ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {sample_wiki_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e829a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5ï¸âƒ£ RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ã¨æ§‹ç¯‰\n",
    "def build_rag_system():\n",
    "    \"\"\"RAGã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰\"\"\"\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«WIKIãƒ‘ã‚¹ã‚’ä½¿ç”¨\n",
    "    wiki_paths = [sample_wiki_dir]\n",
    "    \n",
    "    # RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–\n",
    "    rag_system = WikiRAGSystem(wiki_paths=wiki_paths)\n",
    "    \n",
    "    # ChromaDBåˆæœŸåŒ–\n",
    "    print(\"ğŸ”§ ChromaDBã‚’åˆæœŸåŒ–ä¸­...\")\n",
    "    if not rag_system.initialize_chroma():\n",
    "        print(\"âŒ ChromaDBåˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
    "        return None\n",
    "    \n",
    "    # WIKIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿\n",
    "    print(\"ğŸ“š WIKIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­...\")\n",
    "    documents = []\n",
    "    \n",
    "    for wiki_path in wiki_paths:\n",
    "        if os.path.exists(wiki_path):\n",
    "            for filename in os.listdir(wiki_path):\n",
    "                if filename.endswith('.md'):\n",
    "                    file_path = os.path.join(wiki_path, filename)\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        content = f.read()\n",
    "                    \n",
    "                    doc = Document(\n",
    "                        page_content=content,\n",
    "                        metadata={\n",
    "                            'source': filename,\n",
    "                            'source_type': 'wiki',\n",
    "                            'wiki_path': wiki_path,\n",
    "                            'loaded_at': datetime.now().isoformat()\n",
    "                        }\n",
    "                    )\n",
    "                    documents.append(doc)\n",
    "    \n",
    "    print(f\"ğŸ“„ {len(documents)}å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\")\n",
    "    \n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ãƒ»å‡¦ç†\n",
    "    print(\"âœ‚ï¸ ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²ä¸­...\")\n",
    "    processed_docs = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        # Markdownã‚’ HTMLã«å¤‰æ›ã—ã¦ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º\n",
    "        html = markdown.markdown(doc.page_content)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        clean_text = soup.get_text()\n",
    "        \n",
    "        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²\n",
    "        chunks = rag_system.text_splitter.split_text(clean_text)\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            if len(chunk.strip()) > 50:  # çŸ­ã™ãã‚‹ãƒãƒ£ãƒ³ã‚¯ã¯é™¤å¤–\n",
    "                chunk_doc = Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata={\n",
    "                        **doc.metadata,\n",
    "                        'chunk_index': i,\n",
    "                        'chunk_count': len(chunks)\n",
    "                    }\n",
    "                )\n",
    "                processed_docs.append(chunk_doc)\n",
    "    \n",
    "    print(f\"ğŸ“ {len(processed_docs)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã—ãŸ\")\n",
    "    \n",
    "    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ»æ ¼ç´\n",
    "    print(\"ğŸ”„ ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ»æ ¼ç´ä¸­... (ã“ã‚Œã«ã¯å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™)\")\n",
    "    rag_system.vectorstore.add_documents(processed_docs)\n",
    "    \n",
    "    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º\n",
    "    final_count = rag_system.vectorstore._collection.count()\n",
    "    print(f\"âœ… ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰å®Œäº†ï¼\")\n",
    "    print(f\"ğŸ“Š ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {final_count}\")\n",
    "    \n",
    "    return rag_system\n",
    "\n",
    "# RAGã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰å®Ÿè¡Œ\n",
    "print(\"ğŸš€ RAGã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ä¸­...\")\n",
    "rag_system = build_rag_system()\n",
    "\n",
    "if rag_system:\n",
    "    print(\"\\nğŸ‰ RAGã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "else:\n",
    "    print(\"\\nâŒ RAGã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã«å¤±æ•—ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad86a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6ï¸âƒ£ è³ªå•å¿œç­”æ©Ÿèƒ½ã®å®Ÿè£…\n",
    "def search_knowledge(rag_system, query: str, k: int = 3):\n",
    "    \"\"\"ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢\"\"\"\n",
    "    if not rag_system or not rag_system.vectorstore:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # é¡ä¼¼åº¦æ¤œç´¢\n",
    "        results = rag_system.vectorstore.similarity_search_with_score(query, k=k)\n",
    "        \n",
    "        formatted_results = []\n",
    "        for doc, score in results:\n",
    "            formatted_results.append({\n",
    "                'content': doc.page_content,\n",
    "                'metadata': doc.metadata,\n",
    "                'similarity_score': score,\n",
    "                'source': doc.metadata.get('source', 'unknown')\n",
    "            })\n",
    "        \n",
    "        return formatted_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return []\n",
    "\n",
    "def generate_answer(rag_system, question: str):\n",
    "    \"\"\"è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ç”Ÿæˆ\"\"\"\n",
    "    print(f\"ğŸ” è³ªå•: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # é–¢é€£ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢\n",
    "    search_results = search_knowledge(rag_system, question, k=3)\n",
    "    \n",
    "    if not search_results:\n",
    "        print(\"âŒ é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "        return\n",
    "    \n",
    "    print(\"ğŸ“š é–¢é€£ãƒŠãƒ¬ãƒƒã‚¸:\")\n",
    "    for i, result in enumerate(search_results, 1):\n",
    "        print(f\"\\n{i}. **{result['source']}** (é¡ä¼¼åº¦: {result['similarity_score']:.3f})\")\n",
    "        print(f\"   {result['content'][:200]}...\")\n",
    "    \n",
    "    # æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„æƒ…å ±ã§å›ç­”ä½œæˆ\n",
    "    best_result = search_results[0]\n",
    "    \n",
    "    print(f\"\\nğŸ“ **å›ç­”** (ä¿¡é ¼åº¦: {best_result['similarity_score']:.3f}):\")\n",
    "    print(best_result['content'])\n",
    "    \n",
    "    return {\n",
    "        'answer': best_result['content'],\n",
    "        'sources': search_results,\n",
    "        'confidence': best_result['similarity_score']\n",
    "    }\n",
    "\n",
    "print(\"âœ… è³ªå•å¿œç­”æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¾ã—ãŸï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0de962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7ï¸âƒ£ å®Ÿéš›ã®è³ªå•ãƒ‡ãƒ¢\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«è³ªå•ãƒªã‚¹ãƒˆ\n",
    "sample_questions = [\n",
    "    \"AUTOCREATEãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç‰¹å¾´ã¯ä½•ã§ã™ã‹ï¼Ÿ\",\n",
    "    \"AIè¦–è¦šè‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã‚’æ•™ãˆã¦ãã ã•ã„\",\n",
    "    \"Gradioã®åˆ©ç‚¹ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„\",\n",
    "    \"ChromaDBã®ç‰¹å¾´ã¯ä½•ã§ã™ã‹ï¼Ÿ\",\n",
    "    \"OCRã¨RPAã®çµ„ã¿åˆã‚ã›ã§ã§ãã‚‹ã“ã¨ã¯ï¼Ÿ\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ¯ ã‚µãƒ³ãƒ—ãƒ«è³ªå•ã«ã‚ˆã‚‹å‹•ä½œç¢ºèª\\n\" + \"=\"*60)\n",
    "\n",
    "for i, question in enumerate(sample_questions, 1):\n",
    "    print(f\"\\nã€è³ªå• {i}ã€‘\")\n",
    "    result = generate_answer(rag_system, question)\n",
    "    print(\"\\n\" + \"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2874336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8ï¸âƒ£ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è³ªå•\n",
    "def interactive_qa():\n",
    "    \"\"\"ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªè³ªå•å¿œç­”\"\"\"\n",
    "    print(\"ğŸ’¬ ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è³ªå•ãƒ¢ãƒ¼ãƒ‰\")\n",
    "    print(\"   è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (çµ‚äº†ã™ã‚‹ã«ã¯ 'quit' ã‚’å…¥åŠ›)\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"\\nğŸ¤” è³ªå•: \").strip()\n",
    "        \n",
    "        if question.lower() in ['quit', 'exit', 'çµ‚äº†', 'q']:\n",
    "            print(\"ğŸ‘‹ ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼\")\n",
    "            break\n",
    "        \n",
    "        if not question:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            generate_answer(rag_system, question)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nğŸ‘‹ ä¸­æ–­ã•ã‚Œã¾ã—ãŸ\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰ã®èª¬æ˜\n",
    "print(\"ğŸ® æ¬¡ã®ã‚»ãƒ«ã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªè³ªå•å¿œç­”ã‚’è©¦ã™ã“ã¨ãŒã§ãã¾ã™\")\n",
    "print(\"   ä»¥ä¸‹ã®ã‚ˆã†ãªè³ªå•ã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„:\")\n",
    "print(\"   - 'AIç¤¾é•·ã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ'\")\n",
    "print(\"   - 'ã‚»ãƒ¬ã‚¯ã‚¿ãƒ¼åˆ†æã«ã¤ã„ã¦æ•™ãˆã¦'\") \n",
    "print(\"   - 'kinkaimasu.jpè‡ªå‹•åŒ–ã®åŠ¹æœã¯ï¼Ÿ'\")\n",
    "print(\"\\nâš ï¸  æ³¨æ„: Colabã§ã¯å…¥åŠ›æ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã‚‹å ´åˆãŒã‚ã‚Šã¾ã™\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ac91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9ï¸âƒ£ Gradio Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹\n",
    "def create_gradio_interface():\n",
    "    \"\"\"Gradio Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ä½œæˆ\"\"\"\n",
    "    \n",
    "    def qa_interface(question: str, max_results: int = 3):\n",
    "        \"\"\"Gradioç”¨ã®è³ªå•å¿œç­”ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹\"\"\"\n",
    "        if not question.strip():\n",
    "            return \"è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚\", \"\"\n",
    "        \n",
    "        try:\n",
    "            # æ¤œç´¢å®Ÿè¡Œ\n",
    "            search_results = search_knowledge(rag_system, question, k=max_results)\n",
    "            \n",
    "            if not search_results:\n",
    "                return \"é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\", \"\"\n",
    "            \n",
    "            # å›ç­”æ§‹ç¯‰\n",
    "            best_result = search_results[0]\n",
    "            answer = f\"\"\"**è³ªå•:** {question}\n",
    "\n",
    "**å›ç­”:** ({best_result['similarity_score']:.3f} ä¿¡é ¼åº¦)\n",
    "{best_result['content']}\n",
    "\n",
    "**ã‚½ãƒ¼ã‚¹:** {best_result['source']}\n",
    "\"\"\"\n",
    "            \n",
    "            # é–¢é€£ã‚½ãƒ¼ã‚¹æƒ…å ±\n",
    "            sources_info = \"**é–¢é€£ã‚½ãƒ¼ã‚¹:**\\n\"\n",
    "            for i, result in enumerate(search_results, 1):\n",
    "                sources_info += f\"{i}. {result['source']} (é¡ä¼¼åº¦: {result['similarity_score']:.3f})\\n\"\n",
    "                sources_info += f\"   {result['content'][:100]}...\\n\\n\"\n",
    "            \n",
    "            return answer, sources_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\", \"\"\n",
    "    \n",
    "    # Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®šç¾©\n",
    "    with gr.Blocks(title=\"AUTOCREATE WIKI RAG\", theme=gr.themes.Soft()) as interface:\n",
    "        gr.Markdown(\"\"\"\n",
    "        # ğŸ¤– AUTOCREATE WIKI RAG System\n",
    "        \n",
    "        **AIç¤¾é•·Ã—ç„¡è·CTOä½“åˆ¶**ã«ã‚ˆã‚‹é©æ–°çš„ãªãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ \n",
    "        \n",
    "        æ—¢å­˜ã®WIKIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã€ã‚ãªãŸã®è³ªå•ã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’è‡ªå‹•çš„ã«æ¤œç´¢ã—ã€å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n",
    "        \"\"\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                question_input = gr.Textbox(\n",
    "                    label=\"è³ªå•\",\n",
    "                    placeholder=\"ä¾‹: Gradioã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦ãã ã•ã„\",\n",
    "                    lines=2\n",
    "                )\n",
    "                \n",
    "                max_results = gr.Slider(\n",
    "                    minimum=1,\n",
    "                    maximum=10,\n",
    "                    value=3,\n",
    "                    step=1,\n",
    "                    label=\"æœ€å¤§æ¤œç´¢çµæœæ•°\"\n",
    "                )\n",
    "                \n",
    "                submit_btn = gr.Button(\"ğŸ” è³ªå•ã™ã‚‹\", variant=\"primary\")\n",
    "                \n",
    "            with gr.Column(scale=1):\n",
    "                gr.Markdown(\"\"\"\n",
    "                **ã‚µãƒ³ãƒ—ãƒ«è³ªå•:**\n",
    "                - AUTOCREATEã®ç‰¹å¾´ã¯ï¼Ÿ\n",
    "                - AIè¦–è¦šè‡ªå‹•åŒ–ã¨ã¯ï¼Ÿ\n",
    "                - ChromaDBã®åˆ©ç‚¹ã¯ï¼Ÿ\n",
    "                - OCR+RPAã®åŠ¹æœã¯ï¼Ÿ\n",
    "                \"\"\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                answer_output = gr.Markdown(label=\"å›ç­”\")\n",
    "                \n",
    "            with gr.Column():\n",
    "                sources_output = gr.Markdown(label=\"é–¢é€£ã‚½ãƒ¼ã‚¹\")\n",
    "        \n",
    "        # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©\n",
    "        submit_btn.click(\n",
    "            qa_interface,\n",
    "            inputs=[question_input, max_results],\n",
    "            outputs=[answer_output, sources_output]\n",
    "        )\n",
    "        \n",
    "        question_input.submit(\n",
    "            qa_interface,\n",
    "            inputs=[question_input, max_results],\n",
    "            outputs=[answer_output, sources_output]\n",
    "        )\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ä½œæˆ\n",
    "print(\"ğŸŒ Gradio Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ä½œæˆä¸­...\")\n",
    "gradio_interface = create_gradio_interface()\n",
    "\n",
    "# ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹èµ·å‹•\n",
    "print(\"ğŸš€ Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’èµ·å‹•ã—ã¾ã™...\")\n",
    "gradio_interface.launch(\n",
    "    share=True,  # å…¬é–‹URLç”Ÿæˆ\n",
    "    debug=True,  # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰\n",
    "    show_error=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af1e94f",
   "metadata": {},
   "source": [
    "## ğŸš€ é«˜åº¦ãªæ©Ÿèƒ½ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "### ğŸ’¡ ã“ã®ãƒ‡ãƒ¢ã§å­¦ã‚“ã ã“ã¨\n",
    "\n",
    "1. **ChromaDB ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢**\n",
    "   - å¤šè¨€èªå¯¾å¿œã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨\n",
    "   - åŠ¹ç‡çš„ãªãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ãƒ»ãƒãƒ£ãƒ³ã‚¯åŒ–\n",
    "   - é¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹ã®é–¢é€£æ–‡æ›¸æ¤œç´¢\n",
    "\n",
    "2. **RAG ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰**\n",
    "   - æ—¢å­˜ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è‡ªå‹•ãƒ™ã‚¯ãƒˆãƒ«åŒ–\n",
    "   - è‡ªç„¶è¨€èªã«ã‚ˆã‚‹è³ªå•å¿œç­”\n",
    "   - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ãƒ»å›ç­”ç”Ÿæˆ\n",
    "\n",
    "3. **Gradio Web UI**\n",
    "   - ç›´æ„Ÿçš„ãªWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹\n",
    "   - å…±æœ‰å¯èƒ½ãªãƒ‡ãƒ¢ç’°å¢ƒ\n",
    "   - ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªè³ªå•å¿œç­”\n",
    "\n",
    "### ğŸ”§ ã•ã‚‰ãªã‚‹æ‹¡å¼µå¯èƒ½æ€§\n",
    "\n",
    "- **å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«çµ±åˆ**: OpenAI API, Anthropic API\n",
    "- **ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œ**: ç”»åƒãƒ»éŸ³å£°ãƒ»å‹•ç”»ã®æ¤œç´¢\n",
    "- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°**: æ–°ã—ã„æ–‡æ›¸ã®è‡ªå‹•è¿½åŠ \n",
    "- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**: GPUåŠ é€Ÿã€åˆ†æ•£å‡¦ç†\n",
    "\n",
    "### ğŸŒŸ AUTOCREATE ã®é©æ–°æ€§\n",
    "\n",
    "**AIç¤¾é•·Ã—ç„¡è·CTOä½“åˆ¶**ã«ã‚ˆã‚Šã€å¾“æ¥ã®é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹ã‚’æ ¹æœ¬ã‹ã‚‰å¤‰é©ï¼š\n",
    "\n",
    "- ğŸ’­ **è‡ªç„¶è¨€èªé–‹ç™º**: æ€è€ƒã‚’ãã®ã¾ã¾ã‚³ãƒ¼ãƒ‰ã«\n",
    "- ğŸ¤– **AIè‡ªå‹•åŒ–**: äººé–“ã®å‰µé€ æ€§ã‚’æœ€å¤§åŒ–\n",
    "- ğŸ”„ **ç¶™ç¶šçš„é€²åŒ–**: ã‚·ã‚¹ãƒ†ãƒ ãŒè‡ªå·±æ”¹è‰¯\n",
    "- ğŸŒ **ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹**: çŸ¥è­˜ã®å…±æœ‰ã¨ç™ºå±•\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ ãŠå•ã„åˆã‚ã›ãƒ»å”æ¥­\n",
    "\n",
    "ã“ã®RAGã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿéš›ã®ãƒ“ã‚¸ãƒã‚¹ã«æ´»ç”¨ã—ãŸã„å ´åˆã¯ã€ãŠæ°—è»½ã«ã”ç›¸è«‡ãã ã•ã„ã€‚\n",
    "\n",
    "**AUTOCREATE ãƒãƒ¼ãƒ **\n",
    "- ğŸ¤– AIç¤¾é•·: æˆ¦ç•¥ãƒ»ãƒ“ã‚¸ãƒ§ãƒ³ãƒ»æ„æ€æ±ºå®š\n",
    "- ğŸ‘¨â€ğŸ’» ç„¡è·CTO: æŠ€è¡“å®Ÿè£…ãƒ»ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
