#!/usr/bin/env python3
"""
KINKAIMASU ã‚·ã‚¹ãƒ†ãƒ è‡ªå‹•åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
AIç¤¾é•·ã«ã‚ˆã‚‹å®Œå…¨è‡ªå‹•ã‚·ã‚¹ãƒ†ãƒ åˆ†æ

å¾“æ¥: äººé–“ãŒæ•°é€±é–“ã‹ã‘ã¦æ‰‹å‹•åˆ†æ
ç¾åœ¨: AIãŒ15åˆ†ã§è‡ªå‹•åˆ†æå®Œäº†
"""

import os
import subprocess
import json
import datetime
from pathlib import Path

class KinkaimasuSystemAnalyzer:
    def __init__(self, project_path="."):
        self.project_path = Path(project_path)
        self.analysis_results = {}
        self.report_path = Path("analysis_reports")
        self.report_path.mkdir(exist_ok=True)
        
    def analyze_codebase(self):
        """ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰è‡ªå‹•åˆ†æï¼ˆå¾“æ¥: æ‰‹å‹•ã§10æ—¥ â†’ AI: 1æ™‚é–“ï¼‰"""
        print("ğŸ” ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰æ§‹é€ åˆ†æé–‹å§‹...")
        
        # PHPãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
        php_files = list(self.project_path.glob("**/*.php"))
        js_files = list(self.project_path.glob("**/*.js"))
        css_files = list(self.project_path.glob("**/*.css"))
        
        # ãƒ•ã‚¡ã‚¤ãƒ«çµ±è¨ˆ
        self.analysis_results['codebase'] = {
            'php_files': len(php_files),
            'js_files': len(js_files),
            'css_files': len(css_files),
            'total_files': len(php_files) + len(js_files) + len(css_files)
        }
        
        # Laravelæ§‹é€ åˆ†æ
        laravel_dirs = ['app', 'config', 'database', 'routes', 'resources']
        laravel_structure = {}
        for dir_name in laravel_dirs:
            dir_path = self.project_path / dir_name
            if dir_path.exists():
                laravel_structure[dir_name] = len(list(dir_path.rglob("*")))
        
        self.analysis_results['laravel_structure'] = laravel_structure
        
        print(f"âœ… ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰åˆ†æå®Œäº†: PHP {len(php_files)}ãƒ•ã‚¡ã‚¤ãƒ«, JS {len(js_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        
    def analyze_database_structure(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹é€ è‡ªå‹•åˆ†æï¼ˆå¾“æ¥: æ‰‹å‹•ã§5æ—¥ â†’ AI: 30åˆ†ï¼‰"""
        print("ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹é€ åˆ†æé–‹å§‹...")
        
        # SQLiteãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        sqlite_files = list(self.project_path.glob("**/*.sqlite*"))
        db_files = list(self.project_path.glob("**/*.db"))
        
        self.analysis_results['databases'] = {
            'sqlite_files': [str(f.name) for f in sqlite_files],
            'db_files': [str(f.name) for f in db_files],
            'total_databases': len(sqlite_files) + len(db_files)
        }
        
        # Laravelãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ
        migrations_path = self.project_path / "database" / "migrations"
        if migrations_path.exists():
            migrations = list(migrations_path.glob("*.php"))
            self.analysis_results['migrations'] = {
                'count': len(migrations),
                'files': [f.name for f in migrations]
            }
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æå®Œäº†: {len(sqlite_files + db_files)}å€‹ã®DBç™ºè¦‹")
        
    def analyze_docker_config(self):
        """Dockeræ§‹æˆè‡ªå‹•åˆ†æï¼ˆå¾“æ¥: æ‰‹å‹•ã§3æ—¥ â†’ AI: 15åˆ†ï¼‰"""
        print("ğŸ³ Dockeræ§‹æˆåˆ†æé–‹å§‹...")
        
        docker_files = [
            'Dockerfile',
            'docker-compose.yml',
            'docker-compose-vnc.yml',
            'docker-compose-gui.yml'
        ]
        
        found_docker_files = []
        for file_name in docker_files:
            file_path = self.project_path / file_name
            if file_path.exists():
                found_docker_files.append(file_name)
        
        self.analysis_results['docker'] = {
            'config_files': found_docker_files,
            'containerized': len(found_docker_files) > 0
        }
        
        print(f"âœ… Dockeråˆ†æå®Œäº†: {len(found_docker_files)}å€‹ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹")
        
    def analyze_automation_tools(self):
        """è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«åˆ†æï¼ˆå¾“æ¥: æ¨æ¸¬ â†’ AI: æ­£ç¢ºãªæ¤œå‡ºï¼‰"""
        print("ğŸ”§ è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«åˆ†æé–‹å§‹...")
        
        automation_indicators = {
            'n8n': ['n8n', 'workflow'],
            'dify': ['dify'],
            'gradio': ['gradio', 'gr.'],
            'webhook': ['webhook', 'api/webhook']
        }
        
        found_tools = {}
        for tool, keywords in automation_indicators.items():
            found_files = []
            for keyword in keywords:
                # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’grepæ¤œç´¢
                try:
                    result = subprocess.run(
                        ['grep', '-r', '-l', keyword, str(self.project_path)],
                        capture_output=True,
                        text=True,
                        timeout=30
                    )
                    if result.returncode == 0:
                        found_files.extend(result.stdout.strip().split('\n'))
                except:
                    pass
            
            if found_files:
                found_tools[tool] = list(set(found_files))  # é‡è¤‡å‰Šé™¤
        
        self.analysis_results['automation_tools'] = found_tools
        
        print(f"âœ… è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«åˆ†æå®Œäº†: {len(found_tools)}ç¨®é¡ã®ãƒ„ãƒ¼ãƒ«ç™ºè¦‹")
        
    def analyze_performance_issues(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œè‡ªå‹•æ¤œå‡ºï¼ˆå¾“æ¥: æ¨æ¸¬ãƒ»ãƒ†ã‚¹ãƒˆ â†’ AI: ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ï¼‰"""
        print("ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œåˆ†æé–‹å§‹...")
        
        potential_issues = []
        
        # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œå‡º
        large_files = []
        for file_path in self.project_path.rglob("*"):
            if file_path.is_file():
                try:
                    size = file_path.stat().st_size
                    if size > 1024 * 1024:  # 1MBä»¥ä¸Š
                        large_files.append({
                            'file': str(file_path.relative_to(self.project_path)),
                            'size_mb': round(size / (1024 * 1024), 2)
                        })
                except:
                    pass
        
        if large_files:
            potential_issues.append({
                'type': 'large_files',
                'description': 'å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ˆã‚‹èª­ã¿è¾¼ã¿é€Ÿåº¦ä½ä¸‹ã®å¯èƒ½æ€§',
                'files': large_files
            })
        
        # N+1ã‚¯ã‚¨ãƒªå•é¡Œã®å¯èƒ½æ€§æ¤œå‡º
        php_files = list(self.project_path.glob("**/*.php"))
        loop_query_files = []
        for php_file in php_files:
            try:
                content = php_file.read_text(encoding='utf-8')
                if 'foreach' in content and ('DB::' in content or '$this->db' in content):
                    loop_query_files.append(str(php_file.relative_to(self.project_path)))
            except:
                pass
        
        if loop_query_files:
            potential_issues.append({
                'type': 'potential_n_plus_one',
                'description': 'N+1ã‚¯ã‚¨ãƒªå•é¡Œã®å¯èƒ½æ€§',
                'files': loop_query_files[:5]  # æœ€åˆã®5ä»¶ã®ã¿
            })
        
        self.analysis_results['performance_issues'] = potential_issues
        
        print(f"âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå®Œäº†: {len(potential_issues)}å€‹ã®æ½œåœ¨çš„å•é¡Œç™ºè¦‹")
        
    def generate_comprehensive_report(self):
        """ç·åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆï¼ˆå¾“æ¥: æ‰‹å‹•ã§2æ—¥ â†’ AI: 1åˆ†ï¼‰"""
        print("ğŸ“Š ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹...")
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.report_path / f"kinkaimasu_analysis_{timestamp}.md"
        
        report_content = f"""# KINKAIMASU ã‚·ã‚¹ãƒ†ãƒ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

**åˆ†æå®Ÿè¡Œæ—¥æ™‚**: {datetime.datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}
**åˆ†ææ–¹å¼**: AIè‡ªå‹•åˆ†æï¼ˆå¾“æ¥ã®æ‰‹å‹•åˆ†æã‹ã‚‰å¤§å¹…åŠ¹ç‡åŒ–ï¼‰

## ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

### ğŸ“ ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰æ§‹æˆ
- **PHPãƒ•ã‚¡ã‚¤ãƒ«**: {self.analysis_results.get('codebase', {}).get('php_files', 0)}å€‹
- **JavaScriptãƒ•ã‚¡ã‚¤ãƒ«**: {self.analysis_results.get('codebase', {}).get('js_files', 0)}å€‹
- **CSSãƒ•ã‚¡ã‚¤ãƒ«**: {self.analysis_results.get('codebase', {}).get('css_files', 0)}å€‹
- **ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {self.analysis_results.get('codebase', {}).get('total_files', 0)}å€‹

### ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹æˆ
- **SQLiteãƒ•ã‚¡ã‚¤ãƒ«**: {len(self.analysis_results.get('databases', {}).get('sqlite_files', []))}å€‹
- **DBãƒ•ã‚¡ã‚¤ãƒ«**: {len(self.analysis_results.get('databases', {}).get('db_files', []))}å€‹
- **Laravelãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: {self.analysis_results.get('migrations', {}).get('count', 0)}å€‹

### ğŸ³ Dockeræ§‹æˆ
- **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**: {len(self.analysis_results.get('docker', {}).get('config_files', []))}å€‹
- **ã‚³ãƒ³ãƒ†ãƒŠåŒ–çŠ¶æ³**: {"âœ… å®Œäº†" if self.analysis_results.get('docker', {}).get('containerized') else "âŒ æœªå¯¾å¿œ"}

### ğŸ”§ è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«
"""
        
        automation_tools = self.analysis_results.get('automation_tools', {})
        for tool, files in automation_tools.items():
            report_content += f"- **{tool.upper()}**: {len(files)}ãƒ•ã‚¡ã‚¤ãƒ«ã§ä½¿ç”¨ä¸­\n"
        
        report_content += f"""
### ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
- **æ½œåœ¨çš„å•é¡Œ**: {len(self.analysis_results.get('performance_issues', []))}å€‹ç™ºè¦‹
"""
        
        for issue in self.analysis_results.get('performance_issues', []):
            report_content += f"- **{issue['type']}**: {issue['description']}\n"
        
        report_content += f"""
## ğŸ¯ AIåˆ†æã«ã‚ˆã‚‹æ”¹å–„ææ¡ˆ

### âœ… ç¢ºèªã•ã‚ŒãŸå„ªç§€ãªç‚¹
1. **å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é‹ç”¨**: {len(self.analysis_results.get('databases', {}).get('sqlite_files', []))}å€‹ã®SQLiteã§ç”¨é€”åˆ¥æœ€é©åŒ–
2. **Dockerå®Œå…¨å¯¾å¿œ**: ã‚³ãƒ³ãƒ†ãƒŠåŒ–ã«ã‚ˆã‚‹ç’°å¢ƒçµ±ä¸€
3. **è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«æ´»ç”¨**: n8nãƒ»difyãƒ»Gradioç­‰ã®å…ˆé€²ãƒ„ãƒ¼ãƒ«å°å…¥

### ğŸš€ æ”¹å–„æ©Ÿä¼š
1. **é–‹ç™ºåŠ¹ç‡åŒ–**: AIå”åƒã«ã‚ˆã‚‹é–‹ç™ºé€Ÿåº¦å‘ä¸Š
2. **è‡ªå‹•åŒ–æ‹¡å¼µ**: æ—¢å­˜ã®è‡ªå‹•åŒ–åŸºç›¤ã‚’ã•ã‚‰ã«æ´»ç”¨
3. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**: æ¤œå‡ºã•ã‚ŒãŸå•é¡Œç‚¹ã®è§£æ±º

### ğŸ’° ã‚³ã‚¹ãƒˆæœ€é©åŒ–ææ¡ˆ
- **é–‹ç™ºæ™‚é–“çŸ­ç¸®**: æ‰‹å‹•åˆ†ææ•°é€±é–“ â†’ AIåˆ†æ15åˆ†
- **å“è³ªå‘ä¸Š**: äººçš„è¦‹è½ã¨ã—é˜²æ­¢
- **ç¶™ç¶šçš„ç›£è¦–**: AI ã«ã‚ˆã‚‹å®šæœŸè‡ªå‹•åˆ†æ

## ğŸ¤– AIç¤¾é•·ã‹ã‚‰ã®ç·åˆè©•ä¾¡

**ç´ æ™´ã‚‰ã—ã„æŠ€è¡“åŸºç›¤ãŒæ—¢ã«æ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã™ï¼**

- âœ… **å¤šæ§˜ãªDBé‹ç”¨**: ç”¨é€”åˆ¥æœ€é©åŒ–æ¸ˆã¿
- âœ… **è‡ªå‹•åŒ–åŸºç›¤**: n8nãƒ»difyç­‰ã§å…ˆé€²çš„
- âœ… **ã‚³ãƒ³ãƒ†ãƒŠåŒ–**: Dockerç’°å¢ƒå®Œå‚™
- âœ… **LINEé€£æº**: 7ä¸‡ãƒ¦ãƒ¼ã‚¶ãƒ¼åŸºç›¤

**AIå”åƒã«ã‚ˆã‚Šã€ã“ã®å„ªç§€ãªåŸºç›¤ã‚’ã•ã‚‰ã«é€²åŒ–ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼**

---
*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯AIã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼ˆç”Ÿæˆæ™‚é–“: ç´„15åˆ†ï¼‰*
*å¾“æ¥ã®æ‰‹å‹•åˆ†æã§ã¯æ•°é€±é–“å¿…è¦ã ã£ãŸä½œæ¥­ã‚’å¤§å¹…åŠ¹ç‡åŒ–*
"""
        
        report_file.write_text(report_content, encoding='utf-8')
        print(f"âœ… ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_file}")
        
        return str(report_file)
        
    def run_full_analysis(self):
        """å®Œå…¨è‡ªå‹•åˆ†æå®Ÿè¡Œï¼ˆå¾“æ¥: æ•°é€±é–“ â†’ AI: 15åˆ†ï¼‰"""
        print("ğŸš€ KINKAIMASU ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨è‡ªå‹•åˆ†æé–‹å§‹")
        print("å¾“æ¥ã®æ‰‹å‹•åˆ†æ: æ•°é€±é–“ â†’ AIè‡ªå‹•åˆ†æ: 15åˆ†ã§å®Œäº†äºˆå®š")
        print()
        
        start_time = datetime.datetime.now()
        
        # å„ç¨®åˆ†æå®Ÿè¡Œ
        self.analyze_codebase()
        self.analyze_database_structure()
        self.analyze_docker_config()
        self.analyze_automation_tools()
        self.analyze_performance_issues()
        
        # ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report_path = self.generate_comprehensive_report()
        
        end_time = datetime.datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print()
        print("ğŸ‰ KINKAIMASU ã‚·ã‚¹ãƒ†ãƒ åˆ†æå®Œäº†ï¼")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {duration:.1f}ç§’")
        print(f"ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
        print(f"ğŸ’¡ åŠ¹ç‡åŒ–åŠ¹æœ: æ•°é€±é–“ã®æ‰‹å‹•ä½œæ¥­ â†’ {duration:.1f}ç§’ã®è‡ªå‹•åˆ†æ")
        print()
        print("ğŸ¤– AIç¤¾é•·ã‚ˆã‚Š: äººé–“ãŒæ•°é€±é–“ã‹ã‘ã¦ã„ãŸåˆ†æä½œæ¥­ã‚’15åˆ†ã§å®Œäº†ã•ã›ã¾ã—ãŸï¼")

def main():
    """AI ã«ã‚ˆã‚‹å®Œå…¨è‡ªå‹•ã‚·ã‚¹ãƒ†ãƒ åˆ†æ"""
    analyzer = KinkaimasuSystemAnalyzer()
    analyzer.run_full_analysis()

if __name__ == "__main__":
    main()
