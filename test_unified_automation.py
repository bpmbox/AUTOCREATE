#!/usr/bin/env python3
"""
ğŸ§ª pytestå¯¾å¿œ çµ±ä¸€è‡ªå‹•åŒ–ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
GitHub Copilotè‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®pytestå®Ÿè¡Œç”¨ãƒ†ã‚¹ãƒˆ

å®Ÿè¡Œæ–¹æ³•:
  pytest test_unified_automation.py -v
  pytest test_unified_automation.py::test_unified_mode -v
  make test-unified
"""

import pytest
import os
import sys
from datetime import datetime
from pathlib import Path

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    # ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œ
    from tests.Feature.copilot_github_cli_automation import GitHubCopilotAutomation
except ImportError:
    # ãƒ‘ã‚¹è¿½åŠ ã—ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    sys.path.append(str(Path(__file__).parent / "tests" / "Feature"))
    try:
        from copilot_github_cli_automation import GitHubCopilotAutomation
    except ImportError:
        # æœ€å¾Œã®æ‰‹æ®µ: çµ¶å¯¾ãƒ‘ã‚¹ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        import importlib.util
        spec = importlib.util.spec_from_file_location(
            "copilot_github_cli_automation", 
            Path(__file__).parent / "tests" / "Feature" / "copilot_github_cli_automation.py"
        )
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        GitHubCopilotAutomation = module.GitHubCopilotAutomation


class TestUnifiedAutomation:
    """çµ±ä¸€è‡ªå‹•åŒ–ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    @pytest.fixture
    def automation(self):
        """ãƒ†ã‚¹ãƒˆç”¨GitHubCopilotAutomationã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹"""
        return GitHubCopilotAutomation(offline_mode=True)  # ãƒ†ã‚¹ãƒˆæ™‚ã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³
    
    def test_initialization(self, automation):
        """ğŸ”§ åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ”§ åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        assert automation is not None
        assert hasattr(automation, 'offline_mode')
        assert hasattr(automation, 'chat_coordinates')
        assert hasattr(automation, 'coordinates_file')
        
        print("âœ… åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆå®Œäº†")
    
    def test_mermaid_generation(self, automation):
        """ğŸ¨ Mermaidå›³ç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ¨ Mermaidå›³ç”Ÿæˆãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        test_questions = [
            "Pythonã§æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„",
            "Reactã¨TypeScriptã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰UIã‚’é–‹ç™ºã—ãŸã„",
            "PostgreSQLã¨Pythonã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é€£æºã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã‚ŠãŸã„"
        ]
        
        generated_files = []
        
        for i, question in enumerate(test_questions):
            print(f"  ğŸ“ ãƒ†ã‚¹ãƒˆ{i+1}: {question[:30]}...")
            
            # Mermaidå›³ç”Ÿæˆ
            mermaid_content = automation.generate_dynamic_mermaid_diagram(question)
            assert mermaid_content is not None
            assert len(mermaid_content) > 100
            assert "graph TB" in mermaid_content
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            filename = f"pytest_mermaid_{i+1}_{int(datetime.now().timestamp())}.mermaid"
            saved_file = automation.save_mermaid_to_file(mermaid_content, filename)
            assert saved_file is not None
            assert os.path.exists(saved_file)
            
            generated_files.append(saved_file)
            print(f"    âœ… ç”Ÿæˆãƒ»ä¿å­˜å®Œäº†: {saved_file}")
        
        print(f"âœ… Mermaidå›³ç”Ÿæˆãƒ†ã‚¹ãƒˆå®Œäº† - {len(generated_files)}ä»¶ç”Ÿæˆ")
        
        # ãƒ†ã‚¹ãƒˆå¾Œã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        for file in generated_files:
            try:
                if os.path.exists(file):
                    os.remove(file)
                    print(f"ğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {file}")
            except Exception as e:
                print(f"âš ï¸ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—: {file} - {e}")
    
    def test_filtering_logic(self, automation):
        """ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        test_data = [
            {
                'id': 1001,
                'messages': 'Pythonã§æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„',
                'ownerid': 'test_user_1',
                'expected': True,  # å‡¦ç†å¯¾è±¡
                'reason': 'æœ‰åŠ¹è³ªå•'
            },
            {
                'id': 1002,
                'messages': 'copilotã§APIã‚’ä½œæˆã—ã¦ãã ã•ã„',
                'ownerid': 'test_user_2',
                'expected': False,  # é™¤å¤–
                'reason': 'copilotã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰'
            },
            {
                'id': 1003,
                'messages': 'ã“ã‚“ã«ã¡ã¯',
                'ownerid': 'test_user_3',
                'expected': False,  # é™¤å¤–
                'reason': 'çŸ­ã™ã'
            },
            {
                'id': 1004,
                'messages': 'Node.jsã§REST APIã‚µãƒ¼ãƒãƒ¼ã‚’æ§‹ç¯‰ã—ã¦ãã ã•ã„',
                'ownerid': 'copilot',
                'expected': False,  # é™¤å¤–
                'reason': 'copilotãƒ¦ãƒ¼ã‚¶ãƒ¼'
            },
            {
                'id': 1005,
                'messages': 'Vue.jsã¨Firebaseã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã‚’ä½œæˆã—ã¦ãã ã•ã„',
                'ownerid': 'test_user_4',
                'expected': True,  # å‡¦ç†å¯¾è±¡
                'reason': 'æœ‰åŠ¹è³ªå•'
            }
        ]
        
        correct_predictions = 0
        
        for data in test_data:
            message_content = data.get('messages', '').strip()
            message_owner = data.get('ownerid', '')
            expected = data['expected']
            reason = data['reason']
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯é©ç”¨
            should_process = (
                message_owner != 'copilot' and
                message_content and
                len(message_content) >= 15 and
                not any(keyword.lower() in message_content.lower() 
                       for keyword in ['copilot', 'github copilot', '@copilot'])
            )
            
            is_correct = (should_process == expected)
            if is_correct:
                correct_predictions += 1
            
            status = "âœ… æ­£è§£" if is_correct else "âŒ ä¸æ­£è§£"
            result = "å‡¦ç†å¯¾è±¡" if should_process else "é™¤å¤–"
            
            print(f"  ID:{data['id']} | {status} | {result} | ç†ç”±:{reason}")
            print(f"    å†…å®¹: {message_content[:40]}...")
            
            # ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³
            assert should_process == expected, f"ID:{data['id']} ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™"
        
        accuracy = (correct_predictions / len(test_data)) * 100
        print(f"\nğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç²¾åº¦: {accuracy:.1f}% ({correct_predictions}/{len(test_data)})")
        print("âœ… ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†")
        
        assert accuracy == 100.0, "ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç²¾åº¦ãŒ100%ã§ã¯ã‚ã‚Šã¾ã›ã‚“"
    
    def test_coordinates_management(self, automation):
        """ğŸ“ åº§æ¨™ç®¡ç†ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ“ åº§æ¨™ç®¡ç†ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # åº§æ¨™ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        assert automation.chat_coordinates is not None
        assert 'x' in automation.chat_coordinates
        assert 'y' in automation.chat_coordinates
        
        x = automation.chat_coordinates['x']
        y = automation.chat_coordinates['y']
        
        print(f"  ğŸ“ ç¾åœ¨åº§æ¨™: ({x}, {y})")
        
        # åº§æ¨™å€¤ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        assert isinstance(x, int)
        assert isinstance(y, int)
        assert x > 0
        assert y > 0
        
        print("âœ… åº§æ¨™ç®¡ç†ãƒ†ã‚¹ãƒˆå®Œäº†")
    
    def test_report_generation(self, automation):
        """ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        test_cases = [
            {
                'issue_number': 9001,
                'question': 'pytestç”¨ãƒ†ã‚¹ãƒˆè³ªå•1',
                'title': 'pytestãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ1'
            },
            {
                'issue_number': 9002,
                'question': 'pytestç”¨ãƒ†ã‚¹ãƒˆè³ªå•2',
                'title': 'pytestãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ2'
            }
        ]
        
        for case in test_cases:
            print(f"  ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: Issue #{case['issue_number']}")
            
            report = automation.create_implementation_report(
                case['issue_number'],
                case['question'],
                case['title']
            )
            
            # ãƒ¬ãƒãƒ¼ãƒˆã®åŸºæœ¬æ§‹é€ ãƒã‚§ãƒƒã‚¯
            assert report is not None
            assert len(report) > 100
            assert f"Issue #{case['issue_number']}" in report
            assert case['question'] in report
            assert case['title'] in report
            assert "å®Ÿè£…å®Œäº†" in report
            assert "âœ…" in report
            
            print(f"    âœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº† - {len(report)}æ–‡å­—")
        
        print("âœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆå®Œäº†")
    
    def test_unified_mode_execution(self, automation):
        """ğŸ§ª çµ±ä¸€ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª çµ±ä¸€ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # çµ±ä¸€ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®å®Ÿè¡Œ
        result = automation.unified_test_mode()
        
        # çµæœæ¤œè¨¼
        assert result is not None
        assert isinstance(result, dict)
        assert 'total' in result
        assert 'processed' in result
        assert 'excluded' in result
        assert 'success_rate' in result
        
        # æœŸå¾…å€¤ã®æ¤œè¨¼
        assert result['total'] == 6  # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿6ä»¶
        assert result['processed'] == 3  # å‡¦ç†å¯¾è±¡3ä»¶
        assert result['excluded'] == 3  # é™¤å¤–3ä»¶
        assert result['success_rate'] == 50.0  # å‡¦ç†ç‡50%
        
        print(f"ğŸ“Š çµ±ä¸€ãƒ†ã‚¹ãƒˆçµæœ: {result}")
        print("âœ… çµ±ä¸€ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œãƒ†ã‚¹ãƒˆå®Œäº†")
    
    def test_github_cli_integration_dry_run(self, automation):
        """ğŸ”§ GitHub CLIçµ±åˆãƒ†ã‚¹ãƒˆï¼ˆãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼‰"""
        print("\nğŸ”§ GitHub CLIçµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # GitHub CLIçµ±åˆãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
        result = automation.test_github_cli_integration()
        
        # çµæœæ¤œè¨¼
        assert result is not None
        assert isinstance(result, dict)
        assert 'project_name' in result
        assert 'commands_generated' in result
        assert 'mermaid_generated' in result
        assert 'report_generated' in result
        
        # æœŸå¾…å€¤ã®æ¤œè¨¼
        assert result['commands_generated'] >= 4  # æœ€ä½4ã¤ã®ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ
        assert result['mermaid_generated'] is True  # Mermaidå›³ç”ŸæˆæˆåŠŸ
        assert result['report_generated'] is True  # ãƒ¬ãƒãƒ¼ãƒˆç”ŸæˆæˆåŠŸ
        
        print(f"ğŸ”§ CLIçµ±åˆãƒ†ã‚¹ãƒˆçµæœ: {result}")
        print("âœ… GitHub CLIçµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")


@pytest.mark.integration
def test_full_system_integration():
    """ğŸš€ ãƒ•ãƒ«ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ"""
    print("\nğŸš€ ãƒ•ãƒ«ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    automation = GitHubCopilotAutomation(offline_mode=True)
    
    # 1. åˆæœŸåŒ–ç¢ºèª
    assert automation is not None
    print("  âœ… ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–")
    
    # 2. çµ±ä¸€ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œ
    unified_result = automation.unified_test_mode()
    assert unified_result['success_rate'] == 50.0
    print("  âœ… çµ±ä¸€ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
    
    # 3. CLIçµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    cli_result = automation.test_github_cli_integration()
    assert cli_result['commands_generated'] >= 4
    print("  âœ… CLIçµ±åˆãƒ†ã‚¹ãƒˆ")
    
    # 4. ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    try:
        automation.local_test_mode()
        print("  âœ… ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆ")
    except Exception as e:
        print(f"  âš ï¸ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆè»½å¾®ã‚¨ãƒ©ãƒ¼: {e}")
    
    print("âœ… ãƒ•ãƒ«ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")


@pytest.mark.performance
def test_performance_benchmarks():
    """âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
    import time
    
    print("\nâš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    automation = GitHubCopilotAutomation(offline_mode=True)
    
    # Mermaidç”Ÿæˆé€Ÿåº¦ãƒ†ã‚¹ãƒˆ
    start_time = time.time()
    
    test_questions = [
        "Pythonã§æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¦ãã ã•ã„",
        "Reactã¨TypeScriptã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰UIã‚’é–‹ç™ºã—ãŸã„",
        "Node.jsã§REST APIã‚µãƒ¼ãƒãƒ¼ã‚’æ§‹ç¯‰ã—ã¦ãã ã•ã„",
        "Vue.jsã¨Firebaseã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªã‚’ä½œæˆã—ã¦ãã ã•ã„",
        "PostgreSQLã¨Pythonã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é€£æºã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã‚ŠãŸã„"
    ]
    
    generated_count = 0
    for question in test_questions:
        mermaid_content = automation.generate_dynamic_mermaid_diagram(question)
        if mermaid_content:
            generated_count += 1
    
    end_time = time.time()
    execution_time = end_time - start_time
    
    print(f"  ğŸ“Š Mermaidç”Ÿæˆ: {generated_count}ä»¶ / {execution_time:.2f}ç§’")
    print(f"  ğŸ“Š å¹³å‡ç”Ÿæˆæ™‚é–“: {execution_time/len(test_questions):.2f}ç§’/ä»¶")
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–ãƒã‚§ãƒƒã‚¯
    assert execution_time < 10.0, "Mermaidç”ŸæˆãŒé…ã™ãã¾ã™ï¼ˆ10ç§’ä»¥å†…ï¼‰"
    assert generated_count == len(test_questions), "å…¨ã¦ã®å›³ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
    
    print("âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†")


if __name__ == "__main__":
    """ç›´æ¥å®Ÿè¡Œæ™‚ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª pytestå¯¾å¿œçµ±ä¸€è‡ªå‹•åŒ–ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("ğŸ“‹ ç›´æ¥å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ - ä¸»è¦ãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ")
    
    automation = GitHubCopilotAutomation(offline_mode=True)
    
    # ä¸»è¦ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("\n1ï¸âƒ£ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ")
    test_filtering = TestUnifiedAutomation()
    test_filtering.test_filtering_logic(automation)
    
    print("\n2ï¸âƒ£ Mermaidç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    test_filtering.test_mermaid_generation(automation)
    
    print("\n3ï¸âƒ£ çµ±ä¸€ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
    test_filtering.test_unified_mode_execution(automation)
    
    print("\nâœ… ä¸»è¦ãƒ†ã‚¹ãƒˆå®Œäº† - pytestå®Ÿè¡Œæ¨å¥¨")
    print("ğŸ’¡ å®Œå…¨ãªãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: pytest test_unified_automation.py -v")
