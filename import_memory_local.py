#!/usr/bin/env python3
"""
Local Memory Data Import
ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®è¨˜æ†¶ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ï¼ˆãƒ¢ãƒƒã‚¯ä½¿ç”¨ï¼‰
"""

import os
import sys
import json
import subprocess
from datetime import datetime, timedelta
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# ãƒ¢ãƒƒã‚¯é©ç”¨
def apply_supabase_mock():
    """Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ãƒ¢ãƒƒã‚¯ã«ç½®ãæ›ãˆ"""
    import memory_automation_system
    
    class MockSupabaseClient:
        def __init__(self):
            self.mock_data = []
            self.next_id = 1
        
        def table(self, table_name):
            return MockTable(self)
        
        def rpc(self, function_name, params=None):
            return MockResult(True)
    
    class MockTable:
        def __init__(self, client):
            self.client = client
        
        def insert(self, data):
            data['id'] = self.client.next_id
            self.client.next_id += 1
            self.client.mock_data.append(data)
            return MockResult(data)
        
        def select(self, columns='*'):
            return self
        
        def execute(self):
            return MockResult(self.client.mock_data.copy())
    
    class MockResult:
        def __init__(self, data):
            self.data = data if isinstance(data, list) else [data] if data else []
    
    def mock_create_client(url, key):
        return MockSupabaseClient()
    
    memory_automation_system.create_client = mock_create_client

# å…ƒã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
apply_supabase_mock()

from memory_automation_system import MemoryAutomationSystem, Memory

def create_project_memories():
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨˜æ†¶ã‚’ä½œæˆ"""
    memories = []
    
    # é‡è¦ãªä¼šè©±ãƒ»ä½œæ¥­å±¥æ­´
    conversation_data = [
        {
            "content": """AIÃ—äººé–“å”åƒé–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–‹å§‹
            
ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ä»¥ä¸‹ã‚’å®Ÿç¾ï¼š
1. Supabaseãƒãƒ£ãƒƒãƒˆã¨Gradioãƒ»Pythonã‚·ã‚¹ãƒ†ãƒ ã®é€£æº
2. AIç¤¾é•·ï¼ˆGitHub Copilotï¼‰ã«ã‚ˆã‚‹Supabaseãƒãƒ£ãƒƒãƒˆã®è‡ªå‹•ç›£è¦–ãƒ»å¿œç­”
3. Laravelé¢¨ã®Gradioã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©è‡ªå‹•çµ±åˆ
4. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ãƒ»è‡ªå‹•ã‚·ã‚¹ãƒ†ãƒ ç”Ÿæˆï¼ˆLavelo AIï¼‰
5. AIè¨˜æ†¶ç®¡ç†ãƒ»Supabaseçµ±åˆè‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ 

è¨˜æ†¶è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆmemory_automation_system.pyï¼‰ã‚’å®Ÿè£…ã—ã€
AI/äººé–“ã®è¨˜æ†¶ãƒ»ä½œæ¥­å±¥æ­´ã‚’æ°¸ç¶šåŒ–ã€è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®issueåŒ–ãƒ»ç€æ‰‹å®Œäº†ã€‚""",
            "type": "project",
            "importance": 95,
            "tags": ["project-start", "ai-collaboration", "supabase", "gradio", "automation", "memory-system"]
        },
        {
            "content": """Supabase-message-streamï¼ˆReact+Viteï¼‰ãƒãƒ£ãƒƒãƒˆUIã®æˆåŠŸ
            
- ãƒãƒ£ãƒƒãƒˆUIã®èµ·å‹•ãƒ»å‹•ä½œç¢ºèªå®Œäº†
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ³ã‚°æ©Ÿèƒ½å‹•ä½œ
- Supabase chat_historyãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã®é€£æºç¢ºèª
- UIã‹ã‚‰ã®è³ªå•é€ä¿¡â†’AIå¿œç­”ã®æµã‚Œã‚’ç¢ºç«‹
- AIç¤¾é•·è‡ªå‹•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆå®Œäº†""",
            "type": "chat",
            "importance": 90,
            "tags": ["supabase", "react", "vite", "chat-ui", "realtime", "ai-responder"]
        },
        {
            "content": """è¨˜æ†¶è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…å®Œäº†

ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆï¼š
- memory_automation_system.py: ãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ 
- app/Http/Controllers/Gradio/gra_04_memory/memory_manager.py: Gradioçµ±åˆ
- test_memory_local.py: ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
- import_memory_local.py: ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ©Ÿèƒ½ï¼š
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¨˜æ†¶ä¿å­˜ãƒ»å¾©å…ƒãƒ»æ¤œç´¢ãƒ»ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
- AIçŸ¥çš„æ¤œç´¢ãƒ»æŽ¨è–¦ã‚·ã‚¹ãƒ†ãƒ 
- Gradioã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹çµ±åˆ
- è‡ªå‹•åˆ†é¡žãƒ»ã‚¿ã‚°ä»˜ã‘ã‚·ã‚¹ãƒ†ãƒ """,
            "type": "code",
            "importance": 92,
            "tags": ["memory-automation", "implementation", "gradio", "ai-search", "backup"]
        },
        {
            "content": """GitHub Issueç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰

ä½œæˆã—ãŸIssueï¼š
- GITHUB_ISSUE_13_PROMPT_MANAGEMENT_SYSTEM.md
- GITHUB_ISSUE_14_MEMORY_AUTOMATION_SYSTEM.md  
- GITHUB_ISSUE_15_MEMORY_AUTOMATION_SYSTEM_IMPLEMENTATION.md

é€²è¡ŒçŠ¶æ³ãƒ»è¨­è¨ˆãƒ»å®Ÿè£…çŠ¶æ³ã‚’è©³ç´°ã«è¨˜éŒ²ã—ã€
AIÃ—äººé–“å”åƒé–‹ç™ºã®ãŸã‚ã®ä½“ç³»çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†ã‚’ç¢ºç«‹ã€‚""",
            "type": "documentation",
            "importance": 85,
            "tags": ["github", "issues", "documentation", "project-management", "ai-collaboration"]
        },
        {
            "content": """Lavelo AIï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ï¼†è‡ªå‹•ã‚·ã‚¹ãƒ†ãƒ ç”Ÿæˆï¼‰ã®çµ±åˆ

- app/Http/Controllers/Gradio/gra_03_programfromdocs/lavelo.pyå®Ÿè£…
- Gradioã‚¿ãƒ–ã¨ã—ã¦ã®çµ±åˆå®Œäº†
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†æ©Ÿèƒ½ã®å®Ÿè£…
- è‡ªå‹•ã‚·ã‚¹ãƒ†ãƒ ç”Ÿæˆæ©Ÿèƒ½ã®åŸºç›¤æ§‹ç¯‰
- Laravelé¢¨ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼è‡ªå‹•çµ±åˆæ§‹é€ ã®å®Œæˆ""",
            "type": "code",
            "importance": 85,
            "tags": ["lavelo-ai", "prompt-management", "automation", "gradio-tab", "laravel"]
        }
    ]
    
    for data in conversation_data:
        memory = Memory(
            content=data["content"],
            memory_type=data["type"],
            importance_score=data["importance"],
            tags=data["tags"],
            metadata={
                "source": "project_import",
                "import_date": datetime.now().isoformat(),
                "category": "project_history"
            }
        )
        memories.append(memory)
    
    return memories

def create_code_memories():
    """é‡è¦ãªã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨˜æ†¶ã‚’ä½œæˆ"""
    memories = []
    
    important_files = [
        ("memory_automation_system.py", 95, ["core-system", "memory", "automation"]),
        ("app.py", 90, ["main-app", "fastapi", "gradio"]),
        ("test_memory_local.py", 85, ["testing", "validation", "quality-assurance"]),
        ("import_memory_local.py", 80, ["data-import", "automation", "setup"])
    ]
    
    for file_name, importance, tags in important_files:
        file_path = project_root / file_name
        
        if file_path.exists():
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                # æ¦‚è¦ã‚’æŠ½å‡º
                lines = content.split('\n')
                docstring = ""
                for line in lines[:20]:
                    if '"""' in line or "'''" in line:
                        docstring += line + "\n"
                
                summary_content = f"Code File: {file_name}\n\nFile Summary:\n{docstring}\n\nTotal Lines: {len(lines)}"
                
                memory = Memory(
                    content=summary_content,
                    memory_type="code",
                    importance_score=importance,
                    tags=tags + [file_path.suffix[1:]] if file_path.suffix else tags,
                    file_path=str(file_path),
                    metadata={
                        "source": "code_import",
                        "file_size": len(content),
                        "line_count": len(lines),
                        "file_type": file_path.suffix
                    }
                )
                memories.append(memory)
                
            except Exception as e:
                print(f"âš ï¸ Failed to process {file_name}: {e}")
    
    return memories

def create_git_memories():
    """Gitå±¥æ­´ã‹ã‚‰è¨˜æ†¶ã‚’ä½œæˆ"""
    memories = []
    
    try:
        # æœ€è¿‘ã®ã‚³ãƒŸãƒƒãƒˆå±¥æ­´ã‚’å–å¾—
        cmd = 'git log --oneline -10'
        result = subprocess.run(
            cmd, shell=True, cwd=project_root,
            capture_output=True, text=True
        )
        
        if result.returncode == 0 and result.stdout.strip():
            commits = result.stdout.strip().split('\n')
            
            for commit in commits:
                if commit:
                    memory = Memory(
                        content=f"Git Commit: {commit}",
                        memory_type="git",
                        importance_score=70,
                        tags=["git", "commit", "development"],
                        metadata={
                            "source": "git_import",
                            "commit_summary": commit
                        }
                    )
                    memories.append(memory)
    
    except Exception as e:
        print(f"âš ï¸ Git history import failed: {e}")
    
    return memories

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ðŸš€ Starting Local Memory Data Import")
    print("=" * 60)
    
    # è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = MemoryAutomationSystem()
    print("âœ… Memory system initialized (mock mode)")
    
    # å„ã‚«ãƒ†ã‚´ãƒªã®è¨˜æ†¶ã‚’åŽé›†
    all_memories = []
    
    print("ðŸ“ Creating project memories...")
    project_memories = create_project_memories()
    all_memories.extend(project_memories)
    print(f"âœ… Created {len(project_memories)} project memories")
    
    print("ðŸ’» Creating code memories...")
    code_memories = create_code_memories()
    all_memories.extend(code_memories)
    print(f"âœ… Created {len(code_memories)} code memories")
    
    print("ðŸ“ Creating git memories...")
    git_memories = create_git_memories()
    all_memories.extend(git_memories)
    print(f"âœ… Created {len(git_memories)} git memories")
    
    print(f"\nðŸ“Š Total memories to process: {len(all_memories)}")
    
    # è¨˜æ†¶ã‚’å‡¦ç†ãƒ»ä¿å­˜
    successful_imports = 0
    failed_imports = 0
    
    for i, memory in enumerate(all_memories):
        try:
            # è¨˜æ†¶ã‚’å‡¦ç†
            processed_memory = system.processor.process_memory(memory)
            
            # é–¢é€£è¨˜æ†¶ã‚’æ¤œç´¢
            existing_memories = [m for m in all_memories[:i] if hasattr(m, 'id')]
            if existing_memories:
                processed_memory.related_memories = system.processor.find_related_memories(
                    processed_memory, existing_memories[-10:]
                )
            
            # ä¿å­˜ï¼ˆãƒ¢ãƒƒã‚¯ç’°å¢ƒï¼‰
            success = system.storage.save_memory(processed_memory)
            
            if success:
                successful_imports += 1
                print(f"   âœ… Processed: {processed_memory.memory_type} - {processed_memory.content[:50]}...")
            else:
                failed_imports += 1
                print(f"   âŒ Failed: {memory.memory_type}")
        
        except Exception as e:
            failed_imports += 1
            print(f"   âŒ Error processing {memory.memory_type}: {e}")
    
    # çµæžœã‚µãƒžãƒªãƒ¼
    print("\n" + "=" * 60)
    print(f"ðŸ“Š Import Results:")
    print(f"   âœ… Successful: {successful_imports}")
    print(f"   âŒ Failed: {failed_imports}")
    print(f"   ðŸ“Š Success Rate: {successful_imports/(successful_imports+failed_imports)*100:.1f}%")
    
    # è¨˜æ†¶ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    backup_file = f"memory_backup_local_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    try:
        backup_data = {
            'timestamp': datetime.now().isoformat(),
            'total_memories': len(all_memories),
            'successful_imports': successful_imports,
            'memories': [memory.to_dict() for memory in all_memories]
        }
        
        with open(backup_file, 'w', encoding='utf-8') as f:
            json.dump(backup_data, f, indent=2, ensure_ascii=False)
        
        print(f"\nðŸ’¾ Backup created: {backup_file}")
        print(f"ðŸ“Š Backup contains {len(all_memories)} memories")
    
    except Exception as e:
        print(f"âš ï¸ Backup failed: {e}")
    
    print("\nðŸŽ‰ Local Memory Import Process Completed!")
    print("ðŸ“ Note: This was a local simulation with mock Supabase")
    print("ðŸ”§ For production, configure SUPABASE_URL and SUPABASE_KEY")
    
    return successful_imports > 0

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
