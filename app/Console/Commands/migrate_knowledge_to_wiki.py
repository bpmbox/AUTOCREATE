#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¢å­˜ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®Wikiçµ±åˆãƒ»ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ä»Šã¾ã§ã®è“„ç©ã•ã‚ŒãŸçŸ¥è­˜ã‚’GitHub Wikiã«å®Œå…¨ç§»è¡Œ
"""

import os
import json
import shutil
from pathlib import Path
from datetime import datetime

class WikiKnowledgeMigration:
    """Wiki ãƒŠãƒ¬ãƒƒã‚¸ç§»è¡Œãƒ»çµ±åˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.root_dir = Path(".")
        self.wiki_dir = Path("wiki")
        self.existing_knowledge_dirs = [
            "knowledge_base",
            "conversation_logs", 
            "knowledge_base/auto_generated",
            "knowledge_base/mermaid_test"
        ]
        
        # Wikiå†…ã®æ•´ç†ã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
        self.wiki_structure = {
            "knowledge-base": "æŠ€è¡“ãƒŠãƒ¬ãƒƒã‚¸ãƒ»å®Ÿè£…ä¾‹",
            "ai-memory": "AIè¨˜æ†¶å¾©å…ƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿",
            "mermaid-diagrams": "è‡ªå‹•ç”Ÿæˆå›³è¡¨ãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£",
            "conversation-logs": "è©³ç´°ãªä¼šè©±å±¥æ­´",
            "implementation-examples": "å®Ÿè£…ã‚µãƒ³ãƒ—ãƒ«ãƒ»ã‚³ãƒ¼ãƒ‰ä¾‹",
            "project-history": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå±¥æ­´ãƒ»æˆé•·è¨˜éŒ²"
        }
    
    def run_complete_migration(self):
        """å®Œå…¨ãªãƒŠãƒ¬ãƒƒã‚¸ç§»è¡Œã‚’å®Ÿè¡Œ"""
        print("ğŸš€ æ—¢å­˜ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®Wikiçµ±åˆãƒ»ç§»è¡Œé–‹å§‹")
        print("=" * 60)
        
        # Wiki ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèªãƒ»ä½œæˆ
        self.ensure_wiki_structure()
        
        # æ—¢å­˜ãƒŠãƒ¬ãƒƒã‚¸ã®åé›†ãƒ»åˆ†æ
        all_knowledge = self.collect_existing_knowledge()
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†
        categorized_knowledge = self.categorize_knowledge(all_knowledge)
        
        # Wiki ã«ç§»è¡Œ
        self.migrate_to_wiki(categorized_knowledge)
        
        # çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”Ÿæˆ
        self.generate_master_index(categorized_knowledge)
        
        # Git ã‚³ãƒŸãƒƒãƒˆãƒ»ãƒ—ãƒƒã‚·ãƒ¥
        self.commit_and_push_wiki()
        
        print("\nğŸ‰ ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ Wikiçµ±åˆå®Œäº†ï¼")
        print("ğŸ”— https://github.com/bpmbox/AUTOCREATE/wiki")
    
    def ensure_wiki_structure(self):
        """Wiki ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ç¢ºèªãƒ»ä½œæˆ"""
        print("\nğŸ“ Wiki ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèªä¸­...")
        
        if not self.wiki_dir.exists():
            print("âŒ Wiki ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("å…ˆã« Wikiçµ±åˆãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return False
        
        # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        for dir_name, description in self.wiki_structure.items():
            dir_path = self.wiki_dir / dir_name
            dir_path.mkdir(exist_ok=True)
            print(f"âœ… {dir_name}/ - {description}")
        
        return True
    
    def collect_existing_knowledge(self):
        """æ—¢å­˜ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚’ã™ã¹ã¦åé›†"""
        print("\nğŸ“š æ—¢å­˜ãƒŠãƒ¬ãƒƒã‚¸åé›†ä¸­...")
        
        all_knowledge = {
            "json_files": [],
            "markdown_files": [],
            "mermaid_files": [],
            "html_files": [],
            "conversation_files": [],
            "other_files": []
        }
        
        # å„ãƒŠãƒ¬ãƒƒã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’èµ°æŸ»
        for knowledge_dir in self.existing_knowledge_dirs:
            dir_path = Path(knowledge_dir)
            if dir_path.exists():
                print(f"  ğŸ“‚ {knowledge_dir}/ ã‚’èµ°æŸ»ä¸­...")
                
                for file_path in dir_path.rglob("*"):
                    if file_path.is_file():
                        file_info = {
                            "path": file_path,
                            "relative_path": file_path.relative_to(self.root_dir),
                            "name": file_path.name,
                            "size": file_path.stat().st_size,
                            "modified": datetime.fromtimestamp(file_path.stat().st_mtime),
                            "content_preview": self.get_content_preview(file_path)
                        }
                        
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥ã«åˆ†é¡
                        if file_path.suffix == ".json":
                            all_knowledge["json_files"].append(file_info)
                        elif file_path.suffix == ".md":
                            all_knowledge["markdown_files"].append(file_info)
                        elif file_path.suffix == ".mmd":
                            all_knowledge["mermaid_files"].append(file_info)
                        elif file_path.suffix == ".html":
                            all_knowledge["html_files"].append(file_info)
                        elif "conversation" in file_path.name.lower():
                            all_knowledge["conversation_files"].append(file_info)
                        else:
                            all_knowledge["other_files"].append(file_info)
        
        # çµ±è¨ˆè¡¨ç¤º
        total_files = sum(len(files) for files in all_knowledge.values())
        print(f"\nğŸ“Š åé›†çµæœ:")
        print(f"  - ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {total_files}")
        for file_type, files in all_knowledge.items():
            if files:
                print(f"  - {file_type}: {len(files)}å€‹")
        
        return all_knowledge
    
    def get_content_preview(self, file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—"""
        try:
            if file_path.suffix in [".json", ".md", ".txt", ".mmd"]:
                content = file_path.read_text(encoding='utf-8')
                return content[:200] + "..." if len(content) > 200 else content
            return f"Binary file ({file_path.suffix})"
        except Exception:
            return "èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼"
    
    def categorize_knowledge(self, all_knowledge):
        """ãƒŠãƒ¬ãƒƒã‚¸ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†"""
        print("\nğŸ—‚ï¸ ãƒŠãƒ¬ãƒƒã‚¸ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ä¸­...")
        
        categorized = {
            "technical_knowledge": [],      # æŠ€è¡“çš„ãªãƒŠãƒ¬ãƒƒã‚¸
            "ai_responses": [],            # AIå›ç­”ãƒ»å¯¾è©±
            "implementation_examples": [], # å®Ÿè£…ä¾‹ãƒ»ã‚³ãƒ¼ãƒ‰
            "diagrams": [],               # å›³è¡¨ãƒ»ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ 
            "conversations": [],          # ä¼šè©±å±¥æ­´
            "memory_data": []            # AIè¨˜æ†¶ãƒ‡ãƒ¼ã‚¿
        }
        
        # JSON ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†é¡
        for file_info in all_knowledge["json_files"]:
            try:
                content = json.loads(file_info["path"].read_text(encoding='utf-8'))
                
                if "copilot_response" in content:
                    categorized["ai_responses"].append(file_info)
                elif "memory_id" in content or "memory_" in file_info["name"]:
                    categorized["memory_data"].append(file_info)
                elif "conversation" in file_info["name"].lower():
                    categorized["conversations"].append(file_info)
                else:
                    categorized["technical_knowledge"].append(file_info)
                    
            except Exception:
                categorized["technical_knowledge"].append(file_info)
        
        # Markdown ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†é¡
        for file_info in all_knowledge["markdown_files"]:
            if "implementation" in file_info["name"].lower() or "example" in file_info["name"].lower():
                categorized["implementation_examples"].append(file_info)
            else:
                categorized["technical_knowledge"].append(file_info)
        
        # Mermaidãƒ»HTML ãƒ•ã‚¡ã‚¤ãƒ«
        categorized["diagrams"].extend(all_knowledge["mermaid_files"])
        categorized["diagrams"].extend(all_knowledge["html_files"])
        
        # ä¼šè©±å±¥æ­´
        categorized["conversations"].extend(all_knowledge["conversation_files"])
        
        # åˆ†é¡çµæœè¡¨ç¤º
        print(f"ğŸ“‹ ã‚«ãƒ†ã‚´ãƒªåˆ†é¡çµæœ:")
        for category, files in categorized.items():
            if files:
                print(f"  - {category}: {len(files)}å€‹")
        
        return categorized
    
    def migrate_to_wiki(self, categorized_knowledge):
        """ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«Wikiã«ç§»è¡Œ"""
        print("\nğŸšš Wikiç§»è¡Œå®Ÿè¡Œä¸­...")
        
        migration_map = {
            "technical_knowledge": "knowledge-base",
            "ai_responses": "knowledge-base", 
            "implementation_examples": "implementation-examples",
            "diagrams": "mermaid-diagrams",
            "conversations": "conversation-logs",
            "memory_data": "ai-memory"
        }
        
        migration_stats = {}
        
        for category, files in categorized_knowledge.items():
            if not files:
                continue
                
            target_dir = self.wiki_dir / migration_map[category]
            target_dir.mkdir(exist_ok=True)
            
            migrated_count = 0
            
            for file_info in files:
                try:
                    source_path = file_info["path"]
                    target_path = target_dir / source_path.name
                    
                    # é‡è¤‡å›é¿
                    counter = 1
                    while target_path.exists():
                        name_parts = source_path.stem, counter, source_path.suffix
                        target_path = target_dir / f"{name_parts[0]}_{name_parts[1]}{name_parts[2]}"
                        counter += 1
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼
                    shutil.copy2(source_path, target_path)
                    migrated_count += 1
                    
                except Exception as e:
                    print(f"âš ï¸ ç§»è¡Œã‚¨ãƒ©ãƒ¼: {source_path} -> {e}")
            
            migration_stats[category] = migrated_count
            print(f"âœ… {category} -> {migration_map[category]}: {migrated_count}å€‹")
        
        return migration_stats
    
    def generate_master_index(self, categorized_knowledge):
        """çµ±åˆãƒã‚¹ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆ"""
        print("\nğŸ“‹ çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”Ÿæˆä¸­...")
        
        # æ—¢å­˜ã®Home.mdã‚’èª­ã¿è¾¼ã¿
        home_file = self.wiki_dir / "Home.md"
        existing_content = ""
        if home_file.exists():
            existing_content = home_file.read_text(encoding='utf-8')
        
        # çµ±è¨ˆæƒ…å ±
        total_files = sum(len(files) for files in categorized_knowledge.values())
        
        # æ–°ã—ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
        index_content = f"""# AUTOCREATE AI Wiki - å®Œå…¨ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹

ğŸ¤– **GitHub Copilot AI è‡ªå‹•é–‹ç™ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** - è“„ç©ã•ã‚ŒãŸçŸ¥è­˜ã¨æˆé•·ã®è¨˜éŒ²

## ğŸ“Š ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ

**æœ€çµ‚æ›´æ–°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

### ğŸ’¾ ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ
- **ç·ãƒŠãƒ¬ãƒƒã‚¸ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {total_files}å€‹
- **æŠ€è¡“ãƒŠãƒ¬ãƒƒã‚¸**: {len(categorized_knowledge.get('technical_knowledge', []))}å€‹
- **AIå›ç­”ãƒ»å¯¾è©±**: {len(categorized_knowledge.get('ai_responses', []))}å€‹  
- **å®Ÿè£…ä¾‹ãƒ»ã‚³ãƒ¼ãƒ‰**: {len(categorized_knowledge.get('implementation_examples', []))}å€‹
- **å›³è¡¨ãƒ»ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ **: {len(categorized_knowledge.get('diagrams', []))}å€‹
- **ä¼šè©±å±¥æ­´**: {len(categorized_knowledge.get('conversations', []))}å€‹
- **AIè¨˜æ†¶ãƒ‡ãƒ¼ã‚¿**: {len(categorized_knowledge.get('memory_data', []))}å€‹

## ğŸ§  AIè¨˜æ†¶å¾©å…ƒã‚·ã‚¹ãƒ†ãƒ 

GitHub Copilot AI ãŒã“ã®Wikiã‹ã‚‰å­¦ç¿’ã—ã€éå»ã®çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦æœ€é©ãªå›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

### ğŸ¯ ä¸»è¦æ©Ÿèƒ½
- âœ… **è³ªå•è‡ªå‹•æ¤œå‡ºãƒ»å‡¦ç†** - Supabaseã‹ã‚‰æ–°ç€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç›£è¦–
- âœ… **GitHub Issueè‡ªå‹•ä½œæˆ** - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†è‡ªå‹•åŒ–
- âœ… **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè‡ªå‹•å®Ÿè£…** - packages/ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ã«å®Œå…¨å®Ÿè£…
- âœ… **Mermaidãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ è‡ªå‹•ç”Ÿæˆ** - 5ç¨®é¡ã®å›³è¡¨ã‚¿ã‚¤ãƒ—å¯¾å¿œ
- âœ… **ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹è‡ªå‹•è“„ç©** - JSON + Markdownå½¢å¼
- âœ… **Wikiçµ±åˆãƒ»è¨˜æ†¶å¾©å…ƒ** - ç¶™ç¶šçš„å­¦ç¿’ãƒ»æˆé•·

### ğŸ”„ AIæˆé•·ã‚µã‚¤ã‚¯ãƒ«
**è³ªå• â†’ å­¦ç¿’ â†’ è¨˜æ†¶ â†’ æˆé•· â†’ ã‚ˆã‚Šè‰¯ã„å›ç­”**

## ğŸ“š ãƒŠãƒ¬ãƒƒã‚¸ã‚«ãƒ†ã‚´ãƒª

### ğŸ¯ [æŠ€è¡“ãƒŠãƒ¬ãƒƒã‚¸](knowledge-base/)
ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ»å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹

### ğŸ¤– [AIå¯¾è©±ãƒ»å›ç­”](knowledge-base/)  
GitHub Copilot AI ã®å›ç­”ä¾‹ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ãƒ‡ãƒ¼ã‚¿

### ğŸ’» [å®Ÿè£…ä¾‹ãƒ»ã‚³ãƒ¼ãƒ‰](implementation-examples/)
å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Ÿè£…ãƒ»ã‚³ãƒ¼ãƒ‰ã‚µãƒ³ãƒ—ãƒ«ãƒ»ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### ğŸ¨ [å›³è¡¨ãƒ»ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ ](mermaid-diagrams/)
è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸMermaidå›³è¡¨ãƒ»ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå›³ãƒ»ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ

### ğŸ’¬ [ä¼šè©±å±¥æ­´](conversation-logs/)
è©³ç´°ãªå¯¾è©±è¨˜éŒ²ãƒ»å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ãƒ»ç¶™ç¶šçš„æ”¹å–„ã®è»Œè·¡

### ğŸ§  [AIè¨˜æ†¶ãƒ‡ãƒ¼ã‚¿](ai-memory/)
è¨˜æ†¶å¾©å…ƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ãƒ»å†åˆ©ç”¨å¯èƒ½ãªçŸ¥è­˜

## ğŸš€ AIè‡ªå‹•é–‹ç™ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

### 14ã‚¹ãƒ†ãƒƒãƒ—å®Œå…¨è‡ªå‹•åŒ–ãƒ•ãƒ­ãƒ¼
1. **è³ªå•æ¤œå‡º** - Supabaseç›£è¦–ãƒ»è‡ªå‹•å–å¾—
2. **AIå›ç­”ç”Ÿæˆ** - GitHub Copilotå‡¦ç†
3. **GitHub Issueä½œæˆ** - è‡ªå‹•ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†
4. **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ä½œæˆ** - packages/é…ä¸‹ã«æ•´ç†
5. **ãƒ—ãƒ­ã‚°ãƒ©ãƒ è‡ªå‹•å®Ÿè£…** - å®Œå…¨å‹•ä½œã™ã‚‹ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
6. **Mermaidãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ ç”Ÿæˆ** - 5ç¨®é¡ã®å›³è¡¨è‡ªå‹•ä½œæˆ
7. **Wikiçµ±åˆãƒ»è¨˜æ†¶è“„ç©** - ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ›´æ–°
8. **ç‹¬ç«‹ãƒªãƒã‚¸ãƒˆãƒªä½œæˆ** - ã‚µãƒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–
9. **n8nãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä½œæˆ** - è‡ªå‹•åŒ–ãƒ•ãƒ­ãƒ¼ç”Ÿæˆ
10. **JIRAãƒã‚±ãƒƒãƒˆä½œæˆ** - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†é€£æº
11. **NotionãƒŠãƒ¬ãƒƒã‚¸ç™»éŒ²** - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç®¡ç†
12. **miiboã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé€£æº** - AIçŸ¥è­˜å…±æœ‰
13. **HuggingFace Spaceå…¬é–‹** - ãƒ‡ãƒ¢ãƒ»å…±æœ‰ç’°å¢ƒ
14. **Git Pushãƒ»å®Œäº†é€šçŸ¥** - æˆæœç‰©ã®æ°¸ç¶šåŒ–

### ğŸ”— å¤–éƒ¨é€£æº
- **GitHub**: Issueãƒ»ãƒªãƒã‚¸ãƒˆãƒªãƒ»ã‚µãƒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†
- **Supabase**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒãƒ£ãƒƒãƒˆé€£æº
- **Notion**: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»ãƒŠãƒ¬ãƒƒã‚¸ç®¡ç†
- **JIRA**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»ã‚¿ã‚¹ã‚¯ç®¡ç†
- **miibo**: AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ»çŸ¥è­˜å…±æœ‰
- **HuggingFace**: ãƒ‡ãƒ¢ç’°å¢ƒãƒ»ãƒ¢ãƒ‡ãƒ«å…±æœ‰
- **n8n**: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è‡ªå‹•åŒ–

## ğŸ‰ æˆæœãƒ»å®Ÿç¸¾

### ğŸ“ˆ ç¶™ç¶šçš„æˆé•·è¨˜éŒ²
ã“ã®Wikiã¯ GitHub Copilot AI ã®ã€Œè¨˜æ†¶ã€ã¨ã—ã¦æ©Ÿèƒ½ã—ã€è³ªå•ã™ã‚‹ãŸã³ã«çŸ¥è­˜ãŒè“„ç©ãƒ»æˆé•·ã—ã¦ã„ã¾ã™ã€‚

### ğŸ† é”æˆã—ãŸè‡ªå‹•åŒ–
- **å®Œå…¨ãƒãƒ³ã‚ºã‚ªãƒ•é–‹ç™º**: è³ªå•ã™ã‚‹ã ã‘ã§å®Ÿè£…å®Œäº†
- **çŸ¥è­˜ã®æ°¸ç¶šåŒ–**: Wikiã«ã‚ˆã‚‹è¨˜æ†¶å¾©å…ƒã‚·ã‚¹ãƒ†ãƒ 
- **å›³è¡¨è‡ªå‹•ç”Ÿæˆ**: Mermaidãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ 5ç¨®é¡å¯¾å¿œ
- **å¤šã‚·ã‚¹ãƒ†ãƒ é€£æº**: 8ã¤ã®å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹çµ±åˆ

---

## ğŸ”— ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³

| ã‚«ãƒ†ã‚´ãƒª | èª¬æ˜ | ãƒ•ã‚¡ã‚¤ãƒ«æ•° |
|---------|------|-----------|
| ğŸ“ [knowledge-base/](knowledge-base/) | æŠ€è¡“ãƒŠãƒ¬ãƒƒã‚¸ãƒ»AIå›ç­” | {len(categorized_knowledge.get('technical_knowledge', [])) + len(categorized_knowledge.get('ai_responses', []))} |
| ğŸ’» [implementation-examples/](implementation-examples/) | å®Ÿè£…ä¾‹ãƒ»ã‚³ãƒ¼ãƒ‰ | {len(categorized_knowledge.get('implementation_examples', []))} |
| ğŸ¨ [mermaid-diagrams/](mermaid-diagrams/) | å›³è¡¨ãƒ»ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ  | {len(categorized_knowledge.get('diagrams', []))} |
| ğŸ’¬ [conversation-logs/](conversation-logs/) | ä¼šè©±å±¥æ­´ | {len(categorized_knowledge.get('conversations', []))} |
| ğŸ§  [ai-memory/](ai-memory/) | AIè¨˜æ†¶ãƒ‡ãƒ¼ã‚¿ | {len(categorized_knowledge.get('memory_data', []))} |

---

*ğŸ¤– ã“ã®Wikiã¯ GitHub Copilot AI ã®è‡ªå‹•é–‹ç™ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ã‚ˆã‚Šç¶™ç¶šçš„ã«æ›´æ–°ã•ã‚Œã¾ã™*  
*ğŸ“… Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*  
*ğŸ”— Repository: [AUTOCREATE](https://github.com/bpmbox/AUTOCREATE)*
"""
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿
        home_file.write_text(index_content, encoding='utf-8')
        print(f"âœ… çµ±åˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”Ÿæˆå®Œäº†: {home_file}")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥READMEã‚‚ç”Ÿæˆ
        self.generate_category_readmes(categorized_knowledge)
    
    def generate_category_readmes(self, categorized_knowledge):
        """å„ã‚«ãƒ†ã‚´ãƒªã®READMEã‚’ç”Ÿæˆ"""
        category_descriptions = {
            "knowledge-base": {
                "title": "æŠ€è¡“ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹",
                "description": "GitHub Copilot AI ãŒè“„ç©ã—ãŸæŠ€è¡“çš„çŸ¥è­˜ãƒ»å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ»å›ç­”ä¾‹"
            },
            "implementation-examples": {
                "title": "å®Ÿè£…ä¾‹ãƒ»ã‚³ãƒ¼ãƒ‰ã‚µãƒ³ãƒ—ãƒ«", 
                "description": "å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Ÿè£…ãƒ»ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãƒ»å†åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¼ãƒ‰"
            },
            "mermaid-diagrams": {
                "title": "å›³è¡¨ãƒ»ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ ",
                "description": "è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸMermaidå›³è¡¨ãƒ»ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆå›³ãƒ»å¯è¦–åŒ–è³‡æ–™"
            },
            "conversation-logs": {
                "title": "ä¼šè©±å±¥æ­´ãƒ»å¯¾è©±è¨˜éŒ²",
                "description": "è©³ç´°ãªå¯¾è©±ãƒ—ãƒ­ã‚»ã‚¹ãƒ»å­¦ç¿’ã®è»Œè·¡ãƒ»ç¶™ç¶šçš„æ”¹å–„ã®è¨˜éŒ²"
            },
            "ai-memory": {
                "title": "AIè¨˜æ†¶ãƒ»å­¦ç¿’ãƒ‡ãƒ¼ã‚¿",
                "description": "è¨˜æ†¶å¾©å…ƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ãƒ»çŸ¥è­˜å†åˆ©ç”¨ã‚·ã‚¹ãƒ†ãƒ "
            }
        }
        
        for wiki_dir_name, info in category_descriptions.items():
            readme_path = self.wiki_dir / wiki_dir_name / "README.md"
            
            content = f"""# {info['title']}

{info['description']}

## ğŸ“Š ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¤ã„ã¦

ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯ã€GitHub Copilot AI ã®è‡ªå‹•é–‹ç™ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ç”Ÿæˆãƒ»è“„ç©ã•ã‚ŒãŸ{info['title'].lower()}ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸ¯ æ´»ç”¨æ–¹æ³•

- **å­¦ç¿’å‚è€ƒ**: éå»ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‚è€ƒã«æ–°ã—ã„é–‹ç™ºã‚’é€²ã‚ã‚‹
- **çŸ¥è­˜æ¤œç´¢**: é¡ä¼¼ã®å•é¡Œãƒ»èª²é¡Œã®è§£æ±ºç­–ã‚’æ¢ã™  
- **å“è³ªå‘ä¸Š**: ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãƒ»æ”¹å–„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é©ç”¨
- **ç¶™ç¶šæ”¹å–„**: AIè¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚‹è‡ªå‹•æœ€é©åŒ–

## ğŸ”„ è‡ªå‹•æ›´æ–°

ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ GitHub Copilot AI ã«ã‚ˆã‚Šè‡ªå‹•çš„ã«æ›´æ–°ã•ã‚Œã¾ã™ï¼š

1. **æ–°ã—ã„è³ªå•** â†’ AIå›ç­”ç”Ÿæˆ
2. **çŸ¥è­˜æŠ½å‡º** â†’ ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’  
3. **ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ** â†’ è‡ªå‹•ä¿å­˜
4. **Wikiçµ±åˆ** â†’ è¨˜æ†¶è“„ç©

---

*ğŸ“… Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*  
*ğŸ¤– Generated by GitHub Copilot AI*
"""
            
            readme_path.write_text(content, encoding='utf-8')
            print(f"âœ… ã‚«ãƒ†ã‚´ãƒªREADMEç”Ÿæˆ: {readme_path}")
    
    def commit_and_push_wiki(self):
        """Wikiã®å¤‰æ›´ã‚’Gitã‚³ãƒŸãƒƒãƒˆãƒ»ãƒ—ãƒƒã‚·ãƒ¥"""
        print("\nğŸ”„ Wiki Gitæ›´æ–°ä¸­...")
        
        try:
            import subprocess
            
            os.chdir(self.wiki_dir)
            
            # Git add
            subprocess.run(["git", "add", "."], check=True)
            
            # Git commit
            commit_message = f"""å®Œå…¨ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çµ±åˆå®Œäº† - {datetime.now().strftime('%Y-%m-%d')}

ğŸ¯ æ—¢å­˜ãƒŠãƒ¬ãƒƒã‚¸ã®å®Œå…¨ç§»è¡Œãƒ»æ•´ç†
- æŠ€è¡“ãƒŠãƒ¬ãƒƒã‚¸ãƒ»AIå›ç­”ã®çµ±åˆ
- å®Ÿè£…ä¾‹ãƒ»ã‚³ãƒ¼ãƒ‰ã‚µãƒ³ãƒ—ãƒ«ã®æ•´ç†
- Mermaidå›³è¡¨ãƒ»ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ ã®é›†ç´„
- ä¼šè©±å±¥æ­´ãƒ»å­¦ç¿’è¨˜éŒ²ã®ä¿å­˜
- AIè¨˜æ†¶ãƒ‡ãƒ¼ã‚¿ã®ä½“ç³»åŒ–

ğŸ“Š çµ±åˆçµ±è¨ˆ:
- ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: å¤§å¹…å¢—åŠ 
- ã‚«ãƒ†ã‚´ãƒªåˆ†é¡: 6ç¨®é¡ã§ä½“ç³»åŒ–
- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: å®Œå…¨ãƒªãƒ‹ãƒ¥ãƒ¼ã‚¢ãƒ«
- æ¤œç´¢æ€§: å¤§å¹…å‘ä¸Š

ğŸš€ AIæˆé•·åŸºç›¤ã®å®Œæˆ
GitHub Copilot AI ã®è¨˜æ†¶ãƒ»å­¦ç¿’ãƒ»æˆé•·ã‚·ã‚¹ãƒ†ãƒ ãŒå®Œå…¨ç¨¼åƒé–‹å§‹"""
            
            subprocess.run(["git", "commit", "-m", commit_message], check=True)
            
            # Git push
            subprocess.run(["git", "push", "origin", "master"], check=True)
            
            os.chdir("..")
            
            print("âœ… Wiki Gitæ›´æ–°å®Œäº†")
            
        except subprocess.CalledProcessError as e:
            os.chdir("..")
            print(f"âš ï¸ Gitæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        except Exception as e:
            os.chdir("..")
            print(f"âš ï¸ Gitæ“ä½œã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ æ—¢å­˜ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®Wikiå®Œå…¨çµ±åˆ")
    print("GitHub Copilot AI çŸ¥è­˜ã®æ°¸ç¶šåŒ–ãƒ»ä½“ç³»åŒ–")
    print("-" * 60)
    
    migrator = WikiKnowledgeMigration()
    
    try:
        migrator.run_complete_migration()
        print("\nğŸ‰ ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹Wikiçµ±åˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("ğŸ”— https://github.com/bpmbox/AUTOCREATE/wiki")
        print("ğŸ¤– GitHub Copilot AI ã®å®Œå…¨ãªè¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ãŒç¨¼åƒä¸­")
        
    except Exception as e:
        print(f"âŒ ç§»è¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
