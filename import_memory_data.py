#!/usr/bin/env python3
"""
Memory Data Import Script
æ—¢å­˜ã®ä½œæ¥­å±¥æ­´ãƒ»é‡è¦ãƒ‡ãƒ¼ã‚¿ã‚’Supabase chat_historyãƒ†ãƒ¼ãƒ–ãƒ«ã«è‡ªå‹•æŠ•å…¥
"""

import os
import sys
import json
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
import re
import requests

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from memory_automation_system import MemoryAutomationSystem, Memory

def import_conversation_memories():
    """ã“ã‚Œã¾ã§ã®ä¼šè©±ãƒ»ä½œæ¥­å±¥æ­´ã‚’è¨˜æ†¶ã¨ã—ã¦æŠ•å…¥"""
    print("ğŸ’¬ Importing conversation memories...")
    
    memories = []
    
    # é‡è¦ãªä¼šè©±ãƒ»ä½œæ¥­å±¥æ­´
    conversation_data = [
        {
            "content": """AIÃ—äººé–“å”åƒé–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–‹å§‹
            
ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ä»¥ä¸‹ã‚’å®Ÿç¾ã™ã‚‹ï¼š
1. Supabaseãƒãƒ£ãƒƒãƒˆã¨Gradioãƒ»Pythonã‚·ã‚¹ãƒ†ãƒ ã®é€£æº
2. AIç¤¾é•·ï¼ˆGitHub Copilotï¼‰ã«ã‚ˆã‚‹Supabaseãƒãƒ£ãƒƒãƒˆã®è‡ªå‹•ç›£è¦–ãƒ»å¿œç­”
3. Laravelé¢¨ã®Gradioã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©è‡ªå‹•çµ±åˆ
4. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ãƒ»è‡ªå‹•ã‚·ã‚¹ãƒ†ãƒ ç”Ÿæˆï¼ˆLavelo AIï¼‰
5. AIè¨˜æ†¶ç®¡ç†ãƒ»Supabaseçµ±åˆè‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ """,
            "type": "project",
            "importance": 95,
            "tags": ["project-start", "ai-collaboration", "supabase", "gradio", "automation"]
        },
        {
            "content": """Supabase-message-streamï¼ˆReact+Viteï¼‰ãƒãƒ£ãƒƒãƒˆUIã®æˆåŠŸ
            
- ãƒãƒ£ãƒƒãƒˆUIã®èµ·å‹•ãƒ»å‹•ä½œç¢ºèªå®Œäº†
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ³ã‚°æ©Ÿèƒ½å‹•ä½œ
- Supabase chat_historyãƒ†ãƒ¼ãƒ–ãƒ«ã¨ã®é€£æºç¢ºèª
- UIã‹ã‚‰ã®è³ªå•é€ä¿¡â†’AIå¿œç­”ã®æµã‚Œã‚’ç¢ºç«‹""",
            "type": "chat",
            "importance": 90,
            "tags": ["supabase", "react", "vite", "chat-ui", "realtime"]
        },
        {
            "content": """Gradioãƒ¡ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ï¼ˆapp.pyï¼‰ã®çµ±åˆæˆåŠŸ
            
- è¤‡æ•°ã‚¿ãƒ–çµ±åˆã«ã‚ˆã‚‹çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- Laravelé¢¨ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼æ§‹é€ ã®å®Ÿè£…
- è‡ªå‹•èµ·å‹•é˜²æ­¢ãƒ»ã‚­ãƒ¥ãƒ¼åˆ¶å¾¡ã®å®Œå…¨å®Ÿè£…
- ãƒãƒ¼ãƒˆ7860ã§ã®å®‰å®šå‹•ä½œç¢ºèª""",
            "type": "code",
            "importance": 88,
            "tags": ["gradio", "app.py", "laravel", "integration", "tabs"]
        },
        {
            "content": """AIç¤¾é•·è‡ªå‹•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…å®Œäº†
            
å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«ï¼š
- simple_ai_chat.py: åŸºæœ¬ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½
- copilot_ai_responder.py: Copilotå¿œç­”ã‚·ã‚¹ãƒ†ãƒ 
- copilot_monitorable_ai.py: ç›£è¦–å¯èƒ½AI
- copilot_persistent_monitor.py: æ°¸ç¶šç›£è¦–
- agent_auto_responder.py: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè‡ªå‹•å¿œç­”
- simple_continuous_chat.py: 100å›é€£ç¶šå¯¾è©±ã‚µã‚¤ã‚¯ãƒ«""",
            "type": "git",
            "importance": 92,
            "tags": ["ai-responder", "automation", "copilot", "monitoring", "chat"]
        },
        {
            "content": """Lavelo AIï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†ï¼†è‡ªå‹•ã‚·ã‚¹ãƒ†ãƒ ç”Ÿæˆï¼‰ã®çµ±åˆ
            
- app/Http/Controllers/Gradio/gra_03_programfromdocs/lavelo.pyå®Ÿè£…
- Gradioã‚¿ãƒ–ã¨ã—ã¦ã®çµ±åˆå®Œäº†
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç®¡ç†æ©Ÿèƒ½ã®å®Ÿè£…
- è‡ªå‹•ã‚·ã‚¹ãƒ†ãƒ ç”Ÿæˆæ©Ÿèƒ½ã®åŸºç›¤æ§‹ç¯‰""",
            "type": "code",
            "importance": 85,
            "tags": ["lavelo-ai", "prompt-management", "automation", "gradio-tab"]
        },
        {
            "content": """Supabase ERDè‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰
            
- supabase_schema_explorer.pyå®Ÿè£…
- PostgreSQL publicã‚¹ã‚­ãƒ¼ãƒå…¨ä½“ã®ERDï¼ˆMermaidï¼‰è‡ªå‹•ç”Ÿæˆ
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹é€ ã®å¯è¦–åŒ–
- ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã®è‡ªå‹•å–å¾—ãƒ»åˆ†æ""",
            "type": "database",
            "importance": 80,
            "tags": ["supabase", "erd", "mermaid", "schema", "visualization"]
        },
        {
            "content": """GitHub Issueä½œæˆãƒ»ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
            
ä½œæˆã—ãŸIssueï¼š
- GITHUB_ISSUE_13_PROMPT_MANAGEMENT_SYSTEM.md
- GITHUB_ISSUE_14_MEMORY_AUTOMATION_SYSTEM.md
- GITHUB_ISSUE_15_MEMORY_AUTOMATION_SYSTEM_IMPLEMENTATION.md

é€²è¡ŒçŠ¶æ³ãƒ»è¨­è¨ˆãƒ»å®Ÿè£…çŠ¶æ³ã‚’è©³ç´°ã«è¨˜éŒ²""",
            "type": "documentation",
            "importance": 85,
            "tags": ["github", "issues", "documentation", "project-management"]
        },
        {
            "content": """Git ãƒªãƒã‚¸ãƒˆãƒªç®¡ç†ã¨ãƒªãƒ¢ãƒ¼ãƒˆåŒæœŸ
            
- å®šæœŸçš„ãªgit add/commit/pushã«ã‚ˆã‚‹ãƒªãƒ¢ãƒ¼ãƒˆä¿å­˜
- é‡è¦ãªæˆæœç‰©ã®ç¢ºå®Ÿãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
- ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã«ã‚ˆã‚‹å¤‰æ›´å±¥æ­´ã®è¿½è·¡
- ãƒãƒ¼ãƒ å”åƒã®ãŸã‚ã®åŸºç›¤æ•´å‚™""",
            "type": "git",
            "importance": 75,
            "tags": ["git", "version-control", "backup", "collaboration"]
        }
    ]
    
    for data in conversation_data:
        memory = Memory(
            content=data["content"],
            memory_type=data["type"],
            importance_score=data["importance"],
            tags=data["tags"],
            metadata={
                "source": "conversation_import",
                "import_date": datetime.now().isoformat(),
                "category": "project_history"
            }
        )
        memories.append(memory)
    
    print(f"ğŸ“ Created {len(memories)} conversation memories")
    return memories


def import_code_memories():
    """é‡è¦ãªã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨˜æ†¶ã¨ã—ã¦æŠ•å…¥"""
    print("ğŸ’» Importing code memories...")
    
    memories = []
    
    # é‡è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆ
    important_files = [
        {
            "path": "app.py",
            "importance": 95,
            "tags": ["main-app", "fastapi", "gradio", "integration"]
        },
        {
            "path": "memory_automation_system.py",
            "importance": 90,
            "tags": ["memory", "automation", "core-system"]
        },
        {
            "path": "simple_ai_chat.py",
            "importance": 85,
            "tags": ["ai", "chat", "supabase", "automation"]
        },
        {
            "path": "copilot_ai_responder.py",
            "importance": 88,
            "tags": ["copilot", "ai-responder", "automation"]
        },
        {
            "path": "app/Http/Controllers/Gradio/gra_03_programfromdocs/lavelo.py",
            "importance": 85,
            "tags": ["lavelo-ai", "prompt-management", "gradio"]
        },
        {
            "path": "supabase_schema_explorer.py",
            "importance": 80,
            "tags": ["supabase", "schema", "database", "erd"]
        },
        {
            "path": "routes/web.py",
            "importance": 75,
            "tags": ["routes", "laravel", "web", "api"]
        },
        {
            "path": "requirements.txt",
            "importance": 70,
            "tags": ["dependencies", "python", "packages"]
        }
    ]
    
    for file_info in important_files:
        file_path = project_root / file_info["path"]
        
        if file_path.exists():
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„å ´åˆã¯å…ˆé ­éƒ¨åˆ†ã®ã¿
                if len(content) > 5000:
                    content = content[:5000] + "\n\n... (truncated for memory efficiency)"
                
                memory = Memory(
                    content=f"Code File: {file_info['path']}\n\n{content}",
                    memory_type="code",
                    importance_score=file_info["importance"],
                    tags=file_info["tags"] + [file_path.suffix[1:]] if file_path.suffix else file_info["tags"],
                    file_path=str(file_path),
                    metadata={
                        "source": "code_import",
                        "file_size": len(content),
                        "file_type": file_path.suffix,
                        "import_date": datetime.now().isoformat()
                    }
                )
                memories.append(memory)
                print(f"âœ… Imported {file_info['path']}")
                
            except Exception as e:
                print(f"âŒ Failed to import {file_info['path']}: {e}")
        else:
            print(f"âš ï¸ File not found: {file_info['path']}")
    
    print(f"ğŸ’» Created {len(memories)} code memories")
    return memories


def import_git_memories():
    """Gitå±¥æ­´ã‚’è¨˜æ†¶ã¨ã—ã¦æŠ•å…¥"""
    print("ğŸ“ Importing git memories...")
    
    memories = []
    
    try:
        # æœ€è¿‘ã®ã‚³ãƒŸãƒƒãƒˆå±¥æ­´ã‚’å–å¾—ï¼ˆéå»1é€±é–“ï¼‰
        since_time = datetime.now() - timedelta(days=7)
        since_str = since_time.strftime("%Y-%m-%d")
        
        cmd = f'git log --since="{since_str}" --pretty=format:"%H|%an|%ad|%s" --date=iso'
        result = subprocess.run(
            cmd, shell=True, cwd=project_root,
            capture_output=True, text=True
        )
        
        if result.returncode == 0 and result.stdout.strip():
            commit_lines = result.stdout.strip().split('\n')
            
            for line in commit_lines[:20]:  # æœ€æ–°20ã‚³ãƒŸãƒƒãƒˆ
                if line:
                    parts = line.split('|', 3)
                    if len(parts) >= 4:
                        commit_hash, author, date_str, message = parts
                        
                        # ã‚³ãƒŸãƒƒãƒˆã®è©³ç´°ã‚’å–å¾—
                        diff_cmd = f'git show --stat {commit_hash}'
                        diff_result = subprocess.run(
                            diff_cmd, shell=True, cwd=project_root,
                            capture_output=True, text=True
                        )
                        
                        commit_content = f"Git Commit: {message}\n\nAuthor: {author}\nHash: {commit_hash}\n\n"
                        if diff_result.returncode == 0:
                            commit_content += diff_result.stdout[:2000]  # æœ€åˆã®2000æ–‡å­—
                        
                        # é‡è¦åº¦ã‚’è¨ˆç®—
                        importance = 60
                        important_keywords = ['fix', 'add', 'implement', 'feature', 'system', 'memory', 'ai']
                        for keyword in important_keywords:
                            if keyword.lower() in message.lower():
                                importance += 5
                        
                        memory = Memory(
                            content=commit_content,
                            memory_type="git",
                            importance_score=min(importance, 95),
                            tags=["git", "commit", author.lower().replace(" ", "-")] + 
                                 [kw for kw in important_keywords if kw.lower() in message.lower()],
                            metadata={
                                "source": "git_import",
                                "commit_hash": commit_hash,
                                "author": author,
                                "commit_message": message,
                                "import_date": datetime.now().isoformat()
                            }
                        )
                        memories.append(memory)
            
            print(f"ğŸ“ Created {len(memories)} git memories")
        else:
            print("âš ï¸ No git history found or git not available")
    
    except Exception as e:
        print(f"âŒ Git import error: {e}")
    
    return memories


def import_documentation_memories():
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨˜æ†¶ã¨ã—ã¦æŠ•å…¥"""
    print("ğŸ“š Importing documentation memories...")
    
    memories = []
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
    doc_files = [
        "README.md",
        "AUTOCREATE_COMPANY_BUSINESS_PLAN.md",
        "PROJECT_STRATEGIC_INDEX.md",
        "GITHUB_ISSUE_GENERATION_GUIDE.md",
        "GITHUB_ISSUE_WIKI_RAG_COMPLETION.md",
        "EMERGENCY_MEMORY_FOR_MIYATAKEN999.md"
    ]
    
    for doc_file in doc_files:
        file_path = project_root / doc_file
        
        if file_path.exists():
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                # é•·ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯è¦ç´„
                if len(content) > 10000:
                    content = content[:10000] + "\n\n... (document continues)"
                
                memory = Memory(
                    content=f"Documentation: {doc_file}\n\n{content}",
                    memory_type="documentation",
                    importance_score=80 if "README" in doc_file else 75,
                    tags=["documentation", "markdown", doc_file.lower().replace(".md", "").replace("_", "-")],
                    file_path=str(file_path),
                    metadata={
                        "source": "documentation_import",
                        "document_type": "markdown",
                        "import_date": datetime.now().isoformat()
                    }
                )
                memories.append(memory)
                print(f"âœ… Imported {doc_file}")
                
            except Exception as e:
                print(f"âŒ Failed to import {doc_file}: {e}")
        else:
            print(f"âš ï¸ Documentation not found: {doc_file}")
    
    print(f"ğŸ“š Created {len(memories)} documentation memories")
    return memories


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†: å…¨è¨˜æ†¶ãƒ‡ãƒ¼ã‚¿ã‚’Supabaseã«æŠ•å…¥"""
    print("ğŸš€ Starting Memory Data Import to Supabase")
    print("=" * 60)
    
    # è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = MemoryAutomationSystem()
    
    # å„ã‚«ãƒ†ã‚´ãƒªã®è¨˜æ†¶ã‚’åé›†
    all_memories = []
    
    # ä¼šè©±å±¥æ­´
    conversation_memories = import_conversation_memories()
    all_memories.extend(conversation_memories)
    
    # ã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«
    code_memories = import_code_memories()
    all_memories.extend(code_memories)
    
    # Gitå±¥æ­´
    git_memories = import_git_memories()
    all_memories.extend(git_memories)
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
    doc_memories = import_documentation_memories()
    all_memories.extend(doc_memories)
    
    print(f"\nğŸ“Š Total memories to import: {len(all_memories)}")
    
    # è¨˜æ†¶ã‚’å‡¦ç†ãƒ»ä¿å­˜
    successful_imports = 0
    failed_imports = 0
    
    for i, memory in enumerate(all_memories):
        print(f"ğŸ”„ Processing memory {i+1}/{len(all_memories)}: {memory.memory_type}")
        
        try:
            # è¨˜æ†¶ã‚’å‡¦ç†
            processed_memory = system.processor.process_memory(memory)
            
            # é–¢é€£è¨˜æ†¶ã‚’æ¤œç´¢ï¼ˆæ—¢å­˜ã®è¨˜æ†¶ã‹ã‚‰ï¼‰
            existing_memories = [m for m in all_memories[:i] if hasattr(m, 'id')]
            if existing_memories:
                processed_memory.related_memories = system.processor.find_related_memories(
                    processed_memory, existing_memories[-50:]  # æœ€æ–°50å€‹ã‹ã‚‰é–¢é€£æ€§ã‚’æ¤œç´¢
                )
            
            # Supabaseã«ä¿å­˜
            success = system.storage.save_memory(processed_memory)
            
            if success:
                successful_imports += 1
                print(f"   âœ… Saved (ID: {processed_memory.id})")
            else:
                failed_imports += 1
                print(f"   âŒ Save failed")
        
        except Exception as e:
            failed_imports += 1
            print(f"   âŒ Processing error: {e}")
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print(f"ğŸ“Š Import Results:")
    print(f"   âœ… Successful: {successful_imports}")
    print(f"   âŒ Failed: {failed_imports}")
    print(f"   ğŸ“Š Success Rate: {successful_imports/(successful_imports+failed_imports)*100:.1f}%")
    
    # æœ€çµ‚çµ±è¨ˆã‚’ç”Ÿæˆ
    try:
        report = system.generate_memory_report()
        print(f"\nğŸ“‹ Final Memory Statistics:")
        print(f"   Total memories in system: {report['total_memories']}")
        print(f"   Memory types: {report['memory_types']}")
        print(f"   High importance memories: {report['importance_distribution']['high']}")
        print(f"   Recent activity (24h): {report['recent_activity']['last_24h']}")
    except Exception as e:
        print(f"âš ï¸ Statistics generation error: {e}")
    
    print("\nğŸ‰ Memory Import Process Completed!")
    
    return successful_imports > 0


if __name__ == "__main__":
    # ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
    if not os.getenv('SUPABASE_URL') or not os.getenv('SUPABASE_KEY'):
        print("âš ï¸ Warning: SUPABASE_URL and SUPABASE_KEY environment variables not set")
        print("   Please set them before running this script for actual import")
    
    # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
    success = main()
    
    # çµ‚äº†ã‚³ãƒ¼ãƒ‰
    sys.exit(0 if success else 1)
