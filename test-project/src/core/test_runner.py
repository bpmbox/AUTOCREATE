"""
é«˜åº¦ãªãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³ - Test Runner Module

ãƒ†ã‚¹ãƒˆã®ç™ºè¦‹ã€å®Ÿè¡Œã€çµæœåé›†ã‚’è¡Œã†ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ã‚¸ãƒ³
ä¸¦åˆ—å®Ÿè¡Œã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’ã‚µãƒãƒ¼ãƒˆ
"""

import asyncio
import concurrent.futures
import time
import threading
from typing import List, Dict, Any, Optional, Callable
from pathlib import Path
import json
import logging
from dataclasses import dataclass, field
from enum import Enum

class TestStatus(Enum):
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"""
    PENDING = "pending"
    RUNNING = "running"
    PASSED = "passed"
    FAILED = "failed"
    SKIPPED = "skipped"
    ERROR = "error"

@dataclass
class TestResult:
    """ãƒ†ã‚¹ãƒˆçµæœãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    test_name: str
    status: TestStatus
    duration: float
    message: str = ""
    traceback: str = ""
    assertions: int = 0
    timestamp: float = field(default_factory=time.time)
    metadata: Dict[str, Any] = field(default_factory=dict)

class TestRunner:
    """
    é«˜åº¦ãªãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ³ã‚¸ãƒ³
    
    Features:
    - ä¸¦åˆ—ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—è¡¨ç¤º
    - ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ»é¸æŠå®Ÿè¡Œ
    - çµæœåé›†ãƒ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
    """
    
    def __init__(self, 
                 max_workers: int = 4,
                 timeout: float = 300.0,
                 output_dir: str = "reports"):
        """
        ãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼åˆæœŸåŒ–
        
        Args:
            max_workers: ä¸¦åˆ—å®Ÿè¡Œã™ã‚‹æœ€å¤§ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
            timeout: ãƒ†ã‚¹ãƒˆå…¨ä½“ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰
            output_dir: ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.max_workers = max_workers
        self.timeout = timeout
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # å®Ÿè¡ŒçŠ¶æ…‹ç®¡ç†
        self.tests: List[Callable] = []
        self.results: List[TestResult] = []
        self.running_tests: Dict[str, threading.Thread] = {}
        self.start_time: Optional[float] = None
        self.end_time: Optional[float] = None
        
        # ãƒ­ã‚°è¨­å®š
        self.logger = logging.getLogger(__name__)
        logging.basicConfig(level=logging.INFO)
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'total': 0,
            'passed': 0,
            'failed': 0,
            'skipped': 0,
            'errors': 0
        }
    
    def discover_tests(self, test_dir: str = "tests", pattern: str = "test_*.py") -> List[str]:
        """
        ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ç™ºè¦‹
        
        Args:
            test_dir: ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            pattern: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
            
        Returns:
            ç™ºè¦‹ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
        """
        test_path = Path(test_dir)
        if not test_path.exists():
            self.logger.warning(f"ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {test_dir}")
            return []
        
        test_files = []
        for file_path in test_path.rglob(pattern):
            if file_path.is_file():
                test_files.append(str(file_path))
        
        self.logger.info(f"ç™ºè¦‹ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {len(test_files)}å€‹")
        return sorted(test_files)
    
    def add_test(self, test_func: Callable, name: Optional[str] = None):
        """
        ãƒ†ã‚¹ãƒˆé–¢æ•°ã‚’è¿½åŠ 
        
        Args:
            test_func: ãƒ†ã‚¹ãƒˆé–¢æ•°
            name: ãƒ†ã‚¹ãƒˆåï¼ˆçœç•¥æ™‚ã¯é–¢æ•°åã‚’ä½¿ç”¨ï¼‰
        """
        if name is None:
            name = getattr(test_func, '__name__', str(test_func))
        
        # ãƒ†ã‚¹ãƒˆé–¢æ•°ã«åå‰ã‚’è¨­å®š
        test_func._test_name = name
        self.tests.append(test_func)
        self.logger.debug(f"ãƒ†ã‚¹ãƒˆè¿½åŠ : {name}")
    
    def run_single_test(self, test_func: Callable) -> TestResult:
        """
        å˜ä¸€ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
        
        Args:
            test_func: å®Ÿè¡Œã™ã‚‹ãƒ†ã‚¹ãƒˆé–¢æ•°
            
        Returns:
            ãƒ†ã‚¹ãƒˆçµæœ
        """
        test_name = getattr(test_func, '_test_name', str(test_func))
        start_time = time.time()
        
        try:
            self.logger.info(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–‹å§‹: {test_name}")
            
            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            result = test_func()
            duration = time.time() - start_time
            
            # æˆåŠŸåˆ¤å®š
            if result is None or result is True:
                status = TestStatus.PASSED
                message = "ãƒ†ã‚¹ãƒˆæˆåŠŸ"
            else:
                status = TestStatus.FAILED
                message = f"ãƒ†ã‚¹ãƒˆå¤±æ•—: {result}"
            
            self.logger.info(f"ãƒ†ã‚¹ãƒˆå®Œäº†: {test_name} ({duration:.3f}s)")
            
        except AssertionError as e:
            duration = time.time() - start_time
            status = TestStatus.FAILED
            message = f"ã‚¢ã‚µãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—: {str(e)}"
            traceback = str(e)
            self.logger.error(f"ãƒ†ã‚¹ãƒˆå¤±æ•—: {test_name} - {message}")
            
        except Exception as e:
            duration = time.time() - start_time
            status = TestStatus.ERROR
            message = f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}"
            traceback = str(e)
            self.logger.error(f"ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {test_name} - {message}")
        
        return TestResult(
            test_name=test_name,
            status=status,
            duration=duration,
            message=message,
            traceback=getattr(locals(), 'traceback', ''),
            timestamp=start_time
        )
    
    def run_tests_parallel(self) -> List[TestResult]:
        """
        ãƒ†ã‚¹ãƒˆã‚’ä¸¦åˆ—å®Ÿè¡Œ
        
        Returns:
            å…¨ãƒ†ã‚¹ãƒˆçµæœã®ãƒªã‚¹ãƒˆ
        """
        if not self.tests:
            self.logger.warning("å®Ÿè¡Œã™ã‚‹ãƒ†ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
            return []
        
        self.start_time = time.time()
        self.logger.info(f"ä¸¦åˆ—ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–‹å§‹: {len(self.tests)}å€‹ã®ãƒ†ã‚¹ãƒˆ")
        
        results = []
        
        # ThreadPoolExecutorã§ä¸¦åˆ—å®Ÿè¡Œ
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # å…¨ãƒ†ã‚¹ãƒˆã‚’ä¸¦åˆ—ã§é–‹å§‹
            future_to_test = {
                executor.submit(self.run_single_test, test): test 
                for test in self.tests
            }
            
            # çµæœã‚’é †æ¬¡åé›†
            for future in concurrent.futures.as_completed(future_to_test, timeout=self.timeout):
                test = future_to_test[future]
                try:
                    result = future.result()
                    results.append(result)
                    self._update_stats(result)
                    
                except Exception as e:
                    test_name = getattr(test, '_test_name', str(test))
                    error_result = TestResult(
                        test_name=test_name,
                        status=TestStatus.ERROR,
                        duration=0.0,
                        message=f"ä¸¦åˆ—å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}",
                        traceback=str(e)
                    )
                    results.append(error_result)
                    self._update_stats(error_result)
        
        self.end_time = time.time()
        self.results = results
        
        self.logger.info(f"ä¸¦åˆ—ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå®Œäº†: {len(results)}å€‹ã®çµæœ")
        return results
    
    def run_tests_sequential(self) -> List[TestResult]:
        """
        ãƒ†ã‚¹ãƒˆã‚’é †æ¬¡å®Ÿè¡Œ
        
        Returns:
            å…¨ãƒ†ã‚¹ãƒˆçµæœã®ãƒªã‚¹ãƒˆ
        """
        if not self.tests:
            self.logger.warning("å®Ÿè¡Œã™ã‚‹ãƒ†ã‚¹ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
            return []
        
        self.start_time = time.time()
        self.logger.info(f"é †æ¬¡ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–‹å§‹: {len(self.tests)}å€‹ã®ãƒ†ã‚¹ãƒˆ")
        
        results = []
        
        for i, test in enumerate(self.tests, 1):
            self.logger.info(f"é€²æ—: {i}/{len(self.tests)}")
            
            result = self.run_single_test(test)
            results.append(result)
            self._update_stats(result)
        
        self.end_time = time.time()
        self.results = results
        
        self.logger.info(f"é †æ¬¡ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå®Œäº†: {len(results)}å€‹ã®çµæœ")
        return results
    
    def _update_stats(self, result: TestResult):
        """çµ±è¨ˆæƒ…å ±æ›´æ–°"""
        self.stats['total'] += 1
        
        if result.status == TestStatus.PASSED:
            self.stats['passed'] += 1
        elif result.status == TestStatus.FAILED:
            self.stats['failed'] += 1
        elif result.status == TestStatus.SKIPPED:
            self.stats['skipped'] += 1
        elif result.status == TestStatus.ERROR:
            self.stats['errors'] += 1
    
    def get_summary(self) -> Dict[str, Any]:
        """
        å®Ÿè¡Œã‚µãƒãƒªãƒ¼ã‚’å–å¾—
        
        Returns:
            å®Ÿè¡Œçµæœã®ã‚µãƒãƒªãƒ¼æƒ…å ±
        """
        total_duration = 0.0
        if self.start_time and self.end_time:
            total_duration = self.end_time - self.start_time
        
        return {
            'timestamp': time.time(),
            'total_duration': total_duration,
            'total_tests': len(self.results),
            'statistics': self.stats.copy(),
            'success_rate': (self.stats['passed'] / max(self.stats['total'], 1)) * 100,
            'fastest_test': min((r.duration for r in self.results), default=0.0),
            'slowest_test': max((r.duration for r in self.results), default=0.0),
            'average_duration': sum(r.duration for r in self.results) / max(len(self.results), 1)
        }
    
    def generate_json_report(self, filename: str = "test_results.json"):
        """
        JSONå½¢å¼ã§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        
        Args:
            filename: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
        """
        report_data = {
            'summary': self.get_summary(),
            'results': [
                {
                    'test_name': r.test_name,
                    'status': r.status.value,
                    'duration': r.duration,
                    'message': r.message,
                    'traceback': r.traceback,
                    'assertions': r.assertions,
                    'timestamp': r.timestamp,
                    'metadata': r.metadata
                }
                for r in self.results
            ]
        }
        
        output_path = self.output_dir / filename
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"JSONãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ: {output_path}")
        return output_path
    
    def print_summary(self):
        """å®Ÿè¡Œã‚µãƒãƒªãƒ¼ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›"""
        summary = self.get_summary()
        
        print("\n" + "="*60)
        print("ğŸ§ª ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚µãƒãƒªãƒ¼")
        print("="*60)
        print(f"ğŸ“Š ç·ãƒ†ã‚¹ãƒˆæ•°: {summary['total_tests']}")
        print(f"âœ… æˆåŠŸ: {self.stats['passed']}")
        print(f"âŒ å¤±æ•—: {self.stats['failed']}")
        print(f"âš ï¸  ã‚¨ãƒ©ãƒ¼: {self.stats['errors']}")
        print(f"â­ï¸  ã‚¹ã‚­ãƒƒãƒ—: {self.stats['skipped']}")
        print(f"ğŸ¯ æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {summary['total_duration']:.3f}ç§’")
        print(f"ğŸ“ˆ å¹³å‡å®Ÿè¡Œæ™‚é–“: {summary['average_duration']:.3f}ç§’")
        print(f"ğŸš€ æœ€é€Ÿãƒ†ã‚¹ãƒˆ: {summary['fastest_test']:.3f}ç§’")
        print(f"ğŸŒ æœ€é…ãƒ†ã‚¹ãƒˆ: {summary['slowest_test']:.3f}ç§’")
        print("="*60)
        
        # å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã®è©³ç´°è¡¨ç¤º
        failed_tests = [r for r in self.results if r.status in [TestStatus.FAILED, TestStatus.ERROR]]
        if failed_tests:
            print("\nâŒ å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆ:")
            for result in failed_tests:
                print(f"  â€¢ {result.test_name}: {result.message}")
        
        print()

# ä½¿ç”¨ä¾‹ã¨ãƒ‡ãƒ¢
if __name__ == "__main__":
    
    def sample_test_1():
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆ1: æˆåŠŸ"""
        assert 1 + 1 == 2
        return True
    
    def sample_test_2():
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆ2: å¤±æ•—"""
        assert 1 + 1 == 3  # æ„å›³çš„ãªå¤±æ•—
    
    def sample_test_3():
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆ3: ã‚¨ãƒ©ãƒ¼"""
        raise ValueError("ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ã®ãƒ‡ãƒ¢")
    
    def sample_test_4():
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆ4: æ™‚é–“ã®ã‹ã‹ã‚‹ãƒ†ã‚¹ãƒˆ"""
        import time
        time.sleep(0.5)  # 0.5ç§’å¾…æ©Ÿ
        assert True
    
    # ãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼ã®ä½¿ç”¨ä¾‹
    runner = TestRunner(max_workers=2)
    
    # ãƒ†ã‚¹ãƒˆè¿½åŠ 
    runner.add_test(sample_test_1, "åŸºæœ¬çš„ãªè¨ˆç®—ãƒ†ã‚¹ãƒˆ")
    runner.add_test(sample_test_2, "å¤±æ•—ãƒ‡ãƒ¢ãƒ†ã‚¹ãƒˆ")
    runner.add_test(sample_test_3, "ã‚¨ãƒ©ãƒ¼ãƒ‡ãƒ¢ãƒ†ã‚¹ãƒˆ")
    runner.add_test(sample_test_4, "æ™‚é–“ã®ã‹ã‹ã‚‹ãƒ†ã‚¹ãƒˆ")
    
    # ä¸¦åˆ—å®Ÿè¡Œ
    print("ğŸš€ ä¸¦åˆ—ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
    results = runner.run_tests_parallel()
    
    # çµæœè¡¨ç¤º
    runner.print_summary()
    
    # JSONãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report_path = runner.generate_json_report()
    print(f"ğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
