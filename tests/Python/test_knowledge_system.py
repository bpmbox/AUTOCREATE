#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒŠãƒ¬ãƒƒã‚¸é€£å‹•ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
GitHub Copilotè‡ªå‹•é–‹ç™ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
"""

import os
import json
from datetime import datetime
from pathlib import Path

def test_knowledge_auto_generation():
    """ãƒŠãƒ¬ãƒƒã‚¸è‡ªå‹•ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª ãƒŠãƒ¬ãƒƒã‚¸è‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 50)
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®è³ªå•ãƒ‡ãƒ¼ã‚¿
    test_question = {
        'id': 9999,
        'question': 'React TypeScript ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®APIçµ±åˆã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã¯ï¼Ÿ',
        'user': 'test-user',
        'created': datetime.now().isoformat()
    }
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®Copilotå›ç­”
    test_response = """React TypeScriptãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã®APIçµ±åˆã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ï¼š

## 1. å‹å®‰å…¨ãªAPIè¨­è¨ˆ
```typescript
interface ApiResponse<T> {
  data: T;
  status: number;
  message: string;
}

interface User {
  id: number;
  name: string;
  email: string;
}
```

## 2. Axiosãƒ™ãƒ¼ã‚¹ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
```typescript
import axios from 'axios';

const apiClient = axios.create({
  baseURL: process.env.REACT_APP_API_URL,
  timeout: 10000,
});
```

## 3. React Queryã®æ´»ç”¨
```typescript
import { useQuery } from '@tanstack/react-query';

const useUsers = () => {
  return useQuery<User[]>({
    queryKey: ['users'],
    queryFn: () => apiClient.get<User[]>('/users').then(res => res.data)
  });
};
```

## 4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
```typescript
const ErrorBoundary = ({ children }) => {
  // ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯
};
```

ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚Šã€å‹å®‰å…¨ã§ä¿å®ˆæ€§ã®é«˜ã„APIçµ±åˆãŒå®Ÿç¾ã§ãã¾ã™ã€‚"""
    
    # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    knowledge_dir = Path("knowledge_base/auto_generated")
    knowledge_dir.mkdir(parents=True, exist_ok=True)
    
    # ã‚¿ã‚°æŠ½å‡ºãƒ†ã‚¹ãƒˆ
    def extract_tags_from_question(question):
        tech_keywords = {
            'react': ['react', 'jsx', 'component'],
            'typescript': ['typescript', 'ts'],
            'api': ['api', 'rest', 'graphql', 'endpoint'],
            'frontend': ['frontend', 'ui', 'css', 'html'],
        }
        
        found_tags = []
        question_lower = question.lower()
        
        for category, keywords in tech_keywords.items():
            if any(keyword in question_lower for keyword in keywords):
                found_tags.append(category)
        
        return found_tags if found_tags else ['general']
    
    # ãƒŠãƒ¬ãƒƒã‚¸ã‚¨ãƒ³ãƒˆãƒªä½œæˆ
    knowledge_entry = {
        "timestamp": datetime.now().isoformat(),
        "question": test_question['question'],
        "questioner": test_question['user'],
        "copilot_response": test_response,
        "auto_generated": True,
        "knowledge_type": "copilot-ai-response",
        "tags": extract_tags_from_question(test_question['question']),
        "test_mode": True
    }
    
    print(f"ğŸ“‹ æŠ½å‡ºã•ã‚ŒãŸã‚¿ã‚°: {knowledge_entry['tags']}")
    
    # JSONä¿å­˜
    safe_filename = "test_react_typescript_api_integration"
    filename = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{safe_filename}.json"
    filepath = knowledge_dir / filename
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(knowledge_entry, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ãƒ†ã‚¹ãƒˆãƒŠãƒ¬ãƒƒã‚¸ä¿å­˜: {filepath}")
    
    # Markdownã‚µãƒãƒªãƒ¼ç”Ÿæˆ
    summary_file = knowledge_dir / "README.md"
    
    new_entry = f"""
## {knowledge_entry['timestamp'][:10]} - {knowledge_entry['question'][:100]}

**è³ªå•è€…**: {knowledge_entry['questioner']}  
**ã‚¿ã‚°**: {', '.join(knowledge_entry['tags'])}  
**ç”Ÿæˆæ—¥æ™‚**: {knowledge_entry['timestamp']}  
**ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰**: {knowledge_entry['test_mode']}

### è³ªå•
{knowledge_entry['question']}

### GitHub Copilot AIå›ç­”
{knowledge_entry['copilot_response'][:500]}...

---
"""
    
    # æ—¢å­˜ã®å†…å®¹ã‚’èª­ã¿è¾¼ã¿
    existing_content = ""
    if summary_file.exists():
        with open(summary_file, 'r', encoding='utf-8') as f:
            existing_content = f.read()
    
    if not existing_content:
        content = f"""# AIè‡ªå‹•é–‹ç™ºãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ - ç”ŸæˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹

ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯ã€GitHub Copilot AIãŒè‡ªå‹•ç”Ÿæˆã—ãŸãƒŠãƒ¬ãƒƒã‚¸ãŒè“„ç©ã•ã‚Œã¾ã™ã€‚

## ğŸ“Š çµ±è¨ˆ
- ç”Ÿæˆé–‹å§‹æ—¥: {datetime.now().strftime('%Y-%m-%d')}
- è‡ªå‹•æ›´æ–°: è³ªå•å—ä¿¡æ™‚
- å½¢å¼: JSON + Markdown

## ğŸ§ª ãƒ†ã‚¹ãƒˆã‚¨ãƒ³ãƒˆãƒª
{new_entry}

## ğŸ“‹ ãƒŠãƒ¬ãƒƒã‚¸ã‚¨ãƒ³ãƒˆãƒª
"""
    else:
        content = existing_content + new_entry
    
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"âœ… Markdownã‚µãƒãƒªãƒ¼æ›´æ–°: {summary_file}")
    
    # çµ±è¨ˆè¡¨ç¤º
    json_files = list(knowledge_dir.glob("*.json"))
    print(f"ğŸ“Š ç¾åœ¨ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚¨ãƒ³ãƒˆãƒªæ•°: {len(json_files)}")
    
    # ã‚¿ã‚°åˆ¥çµ±è¨ˆ
    tag_stats = {}
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                for tag in data.get('tags', []):
                    tag_stats[tag] = tag_stats.get(tag, 0) + 1
        except:
            continue
    
    print("ğŸ·ï¸ ã‚¿ã‚°åˆ¥çµ±è¨ˆ:")
    for tag, count in sorted(tag_stats.items()):
        print(f"  - {tag}: {count}ä»¶")
    
    print("\nâœ… ãƒŠãƒ¬ãƒƒã‚¸è‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("ğŸ¯ å®Ÿéš›ã®è³ªå•ãŒæ¥ãŸæ™‚ã«åŒæ§˜ã®å‡¦ç†ãŒè‡ªå‹•å®Ÿè¡Œã•ã‚Œã¾ã™")
    
    return True

if __name__ == "__main__":
    test_knowledge_auto_generation()
