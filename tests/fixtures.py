"""
ğŸ§ª Custom Pytest Fixtures and Utilities
è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£ã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
"""

import pytest
import os
import tempfile
import json
from pathlib import Path
from unittest.mock import Mock, patch

@pytest.fixture(scope="session")
def test_data_dir():
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"""
    return Path(__file__).parent / "test_data"

@pytest.fixture
def sample_chat_messages():
    """ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³"""
    return [
        {
            'id': 'msg-001',
            'user_message': 'Reactã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆã—ãŸã„',
            'user_name': 'frontend_dev',
            'created_at': '2025-06-28T10:00:00Z',
            'channel': 'development'
        },
        {
            'id': 'msg-002', 
            'user_message': 'Python APIã‚µãƒ¼ãƒãƒ¼ã®å®Ÿè£…',
            'user_name': 'backend_dev',
            'created_at': '2025-06-28T11:00:00Z',
            'channel': 'backend'
        },
        {
            'id': 'msg-003',
            'user_message': 'ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆã®ç›¸è«‡',
            'user_name': 'db_admin',
            'created_at': '2025-06-28T12:00:00Z',
            'channel': 'database'
        }
    ]

@pytest.fixture
def mock_supabase_client():
    """ãƒ¢ãƒƒã‚¯Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    mock_client = Mock()
    mock_table = Mock()
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    sample_data = {
        'data': [
            {
                'id': 'test-123',
                'user_message': 'ãƒ¢ãƒƒã‚¯ãƒ†ã‚¹ãƒˆç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸',
                'user_name': 'mock_user',
                'created_at': '2025-06-28T12:00:00Z'
            }
        ]
    }
    
    mock_table.select.return_value.order.return_value.limit.return_value.execute.return_value = sample_data
    mock_client.table.return_value = mock_table
    
    return mock_client

@pytest.fixture
def mock_github_cli():
    """ãƒ¢ãƒƒã‚¯GitHub CLIã‚³ãƒãƒ³ãƒ‰"""
    def mock_subprocess_run(*args, **kwargs):
        mock_result = Mock()
        mock_result.returncode = 0
        mock_result.stdout = "Test output"
        mock_result.stderr = ""
        return mock_result
    
    with patch('subprocess.run', side_effect=mock_subprocess_run):
        yield mock_subprocess_run

@pytest.fixture
def clean_environment():
    """ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ†ã‚¹ãƒˆç’°å¢ƒ"""
    # ç’°å¢ƒå¤‰æ•°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    original_env = os.environ.copy()
    
    # ãƒ†ã‚¹ãƒˆç”¨ç’°å¢ƒå¤‰æ•°è¨­å®š
    test_env = {
        'DEBUG_MODE': 'True',
        'TEST_MODE': 'True',
        'OFFLINE_MODE': 'True'
    }
    
    for key, value in test_env.items():
        os.environ[key] = value
    
    yield test_env
    
    # ç’°å¢ƒå¤‰æ•°ã®å¾©å…ƒ
    os.environ.clear()
    os.environ.update(original_env)

@pytest.fixture
def temp_workspace(tmp_path):
    """ä¸€æ™‚çš„ãªãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹"""
    workspace = tmp_path / "test_workspace"
    workspace.mkdir()
    
    # åŸºæœ¬çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’ä½œæˆ
    (workspace / "src").mkdir()
    (workspace / "tests").mkdir()
    (workspace / "docs").mkdir()
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    (workspace / "README.md").write_text("# Test Project")
    (workspace / "package.json").write_text('{"name": "test-project"}')
    
    original_cwd = os.getcwd()
    os.chdir(workspace)
    
    yield workspace
    
    os.chdir(original_cwd)

@pytest.fixture
def mermaid_validator():
    """Mermaidå›³ã®æ¤œè¨¼ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    def validate_mermaid_syntax(content):
        """åŸºæœ¬çš„ãªMermaidæ§‹æ–‡ãƒã‚§ãƒƒã‚¯"""
        checks = {
            'has_graph_declaration': content.strip().startswith('graph TB'),
            'has_arrows': '-->' in content,
            'has_nodes': '[' in content and ']' in content,
            'has_start_node': 'START[' in content,
            'has_end_node': 'END[' in content,
            'proper_line_breaks': '\n' in content,
            'no_syntax_errors': not any(error in content for error in ['<error>', 'undefined'])
        }
        return checks
    
    def validate_mermaid_content(content, expected_keywords):
        """Mermaidå›³ã®å†…å®¹æ¤œè¨¼"""
        content_checks = {
            'contains_keywords': all(keyword in content for keyword in expected_keywords),
            'appropriate_length': 100 < len(content) < 5000,
            'japanese_support': any(ord(char) > 127 for char in content) if any(ord(char) > 127 for char in ''.join(expected_keywords)) else True
        }
        return content_checks
    
    return {
        'validate_syntax': validate_mermaid_syntax,
        'validate_content': validate_mermaid_content
    }

@pytest.fixture
def performance_monitor():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    import time
    
    class PerformanceMonitor:
        def __init__(self):
            self.start_time = None
            self.measurements = {}
        
        def start(self):
            self.start_time = time.time()
        
        def measure(self, operation_name):
            if self.start_time is None:
                raise ValueError("start()ã‚’æœ€åˆã«å‘¼ã³å‡ºã—ã¦ãã ã•ã„")
            
            elapsed = time.time() - self.start_time
            self.measurements[operation_name] = elapsed
            return elapsed
        
        def get_measurements(self):
            return self.measurements.copy()
        
        def assert_performance(self, operation_name, max_seconds):
            if operation_name not in self.measurements:
                raise ValueError(f"æ¸¬å®šã•ã‚Œã¦ã„ãªã„æ“ä½œ: {operation_name}")
            
            actual_time = self.measurements[operation_name]
            assert actual_time <= max_seconds, f"{operation_name}ã®å®Ÿè¡Œæ™‚é–“ãŒåˆ¶é™ã‚’è¶…é: {actual_time:.2f}s > {max_seconds}s"
    
    return PerformanceMonitor()

@pytest.fixture
def github_issue_mock():
    """GitHub Issueæ“ä½œã®ãƒ¢ãƒƒã‚¯"""
    class GitHubIssueMock:
        def __init__(self):
            self.issues = []
            self.next_id = 1
        
        def create_issue(self, title, body, labels=None):
            issue = {
                'id': self.next_id,
                'title': title,
                'body': body,
                'labels': labels or [],
                'state': 'open',
                'created_at': '2025-06-28T12:00:00Z'
            }
            self.issues.append(issue)
            self.next_id += 1
            return issue
        
        def get_issue(self, issue_id):
            for issue in self.issues:
                if issue['id'] == issue_id:
                    return issue
            return None
        
        def list_issues(self, state='open'):
            return [issue for issue in self.issues if issue['state'] == state]
        
        def close_issue(self, issue_id, comment=None):
            issue = self.get_issue(issue_id)
            if issue:
                issue['state'] = 'closed'
                if comment:
                    issue['close_comment'] = comment
                return True
            return False
    
    return GitHubIssueMock()

@pytest.fixture(autouse=True)
def test_logging(caplog):
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ­ã‚°è¨­å®š"""
    import logging
    caplog.set_level(logging.DEBUG)
    yield caplog

# ãƒãƒ¼ã‚«ãƒ¼ç”¨ã®ã‚¹ã‚­ãƒƒãƒ—ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£
@pytest.fixture(autouse=True)
def skip_online_tests_if_offline(request):
    """ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç’°å¢ƒã§ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—"""
    if request.node.get_closest_marker("online"):
        if os.getenv('OFFLINE_MODE', 'False').lower() == 'true':
            pytest.skip("ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã®ãŸã‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—")

@pytest.fixture(autouse=True) 
def skip_slow_tests_if_fast_mode(request):
    """é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ã§ã‚¹ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—"""
    if request.node.get_closest_marker("slow"):
        if os.getenv('FAST_TEST_MODE', 'False').lower() == 'true':
            pytest.skip("é«˜é€Ÿãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®ãŸã‚ã‚¹ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—")

# ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£
@pytest.fixture
def error_simulation():
    """ã‚¨ãƒ©ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    class ErrorSimulator:
        @staticmethod
        def network_error():
            """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
            from requests.exceptions import ConnectionError
            raise ConnectionError("æ¨¡æ“¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼")
        
        @staticmethod
        def file_permission_error():
            """ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
            raise PermissionError("æ¨¡æ“¬ãƒ•ã‚¡ã‚¤ãƒ«æ¨©é™ã‚¨ãƒ©ãƒ¼")
        
        @staticmethod
        def api_rate_limit_error():
            """APIåˆ¶é™ã‚¨ãƒ©ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
            class MockResponse:
                status_code = 429
                text = "Rate limit exceeded"
            
            from requests.exceptions import HTTPError
            error = HTTPError("429 Client Error: Too Many Requests")
            error.response = MockResponse()
            raise error
    
    return ErrorSimulator()
